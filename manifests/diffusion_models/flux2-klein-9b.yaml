id: flux2-klein-9b
name: "FLUX.2 Klein 9B"
type: diffusion_model
architecture: flux
author: unsloth / shimmyshimmer
license: flux-2-klein-non-commercial
homepage: https://huggingface.co/unsloth/FLUX.2-klein-9B-GGUF
description: |
  FLUX.2 Klein 9B from Unsloth, available as GGUF quantizations.
  Successor to FLUX.1 with improved image quality and editing capabilities.
  Supports text-to-image and image editing workflows.
  Uses FLUX.2 VAE and Qwen 3 8B text encoder.
  Requires ComfyUI-GGUF custom node for GGUF variants.

variants:
  - id: bf16
    file: flux-2-klein-9b-BF16.gguf
    url: https://huggingface.co/unsloth/FLUX.2-klein-9B-GGUF/resolve/main/flux-2-klein-9b-BF16.gguf
    sha256: "d4a80a1885c8b952d8f8d171ab3d1cac166ae7223d5ff4b5ee2d40932ce9fd58"
    size: 18200000000
    format: gguf
    precision: bf16
    vram_required: 20480
    vram_recommended: 24576
    note: "Full precision bf16 GGUF. Best quality."

  - id: f16
    file: flux-2-klein-9b-F16.gguf
    url: https://huggingface.co/unsloth/FLUX.2-klein-9B-GGUF/resolve/main/flux-2-klein-9b-F16.gguf
    sha256: "f82a83fd13542f3d6ac76e67e1fe60c08cdceddab856337f1b9ec534d9b5ca6f"
    size: 18200000000
    format: gguf
    precision: f16
    vram_required: 20480
    vram_recommended: 24576
    note: "Full precision fp16 GGUF."

  - id: gguf-q8-0
    file: flux-2-klein-9b-Q8_0.gguf
    url: https://huggingface.co/unsloth/FLUX.2-klein-9B-GGUF/resolve/main/flux-2-klein-9b-Q8_0.gguf
    sha256: "824b14b3d89f62779db9bcfe6af9084a52e1a3880e7ff93d50943969f9e25b27"
    size: 9980000000
    format: gguf
    precision: q8_0
    vram_required: 12288
    vram_recommended: 16384
    note: "GGUF Q8_0 — highest quality quantization."

  - id: gguf-q6-k
    file: flux-2-klein-9b-Q6_K.gguf
    url: https://huggingface.co/unsloth/FLUX.2-klein-9B-GGUF/resolve/main/flux-2-klein-9b-Q6_K.gguf
    sha256: "e19f643ba4b66ed5b779bc6283f0629363cabb0490cb06823cadb30a549eda5d"
    size: 7870000000
    format: gguf
    precision: q6_k
    vram_required: 10240
    vram_recommended: 12288
    note: "GGUF Q6_K — very good quality/size balance."

  - id: gguf-q5-k-m
    file: flux-2-klein-9b-Q5_K_M.gguf
    url: https://huggingface.co/unsloth/FLUX.2-klein-9B-GGUF/resolve/main/flux-2-klein-9b-Q5_K_M.gguf
    sha256: "bac097be5094c7c3fba993a1e57c6bb9cfc1dd0b33d608cc419311334aa4d015"
    size: 7020000000
    format: gguf
    precision: q5_k_m
    vram_required: 8192
    vram_recommended: 12288
    note: "GGUF Q5_K_M — recommended for 12GB+ GPUs."

  - id: gguf-q5-k-s
    file: flux-2-klein-9b-Q5_K_S.gguf
    url: https://huggingface.co/unsloth/FLUX.2-klein-9B-GGUF/resolve/main/flux-2-klein-9b-Q5_K_S.gguf
    sha256: "5cd600987443bafb0c04ccde87f5e7b083a8fcab26cdd8c8f2b331dde25cd010"
    size: 6940000000
    format: gguf
    precision: q5_k_s
    vram_required: 8192
    vram_recommended: 12288
    note: "GGUF Q5_K_S — smaller Q5 variant."

  - id: gguf-q4-k-m
    file: flux-2-klein-9b-Q4_K_M.gguf
    url: https://huggingface.co/unsloth/FLUX.2-klein-9B-GGUF/resolve/main/flux-2-klein-9b-Q4_K_M.gguf
    sha256: "262df1a3a98bc328911e03d4d0f5d7e3b1397477a2c485b24509b6d115259aef"
    size: 5910000000
    format: gguf
    precision: q4_k_m
    vram_required: 8192
    vram_recommended: 10240
    note: "GGUF Q4_K_M — good for 8GB GPUs."

  - id: gguf-q4-k-s
    file: flux-2-klein-9b-Q4_K_S.gguf
    url: https://huggingface.co/unsloth/FLUX.2-klein-9B-GGUF/resolve/main/flux-2-klein-9b-Q4_K_S.gguf
    sha256: "ee1c0373abb438f1fda472ac15775a0b538bf6f464ec978eaaf8a2a96a42cac3"
    size: 5830000000
    format: gguf
    precision: q4_k_s
    vram_required: 8192
    vram_recommended: 10240
    note: "GGUF Q4_K_S — smaller Q4 variant."

  - id: gguf-q4-1
    file: flux-2-klein-9b-Q4_1.gguf
    url: https://huggingface.co/unsloth/FLUX.2-klein-9B-GGUF/resolve/main/flux-2-klein-9b-Q4_1.gguf
    sha256: "96c219d318d3ef9000159a11a6098e46da30a03848fdd375b7dfa3fc84199895"
    size: 6160000000
    format: gguf
    precision: q4_1
    vram_required: 8192
    vram_recommended: 10240
    note: "GGUF Q4_1."

  - id: gguf-q4-0
    file: flux-2-klein-9b-Q4_0.gguf
    url: https://huggingface.co/unsloth/FLUX.2-klein-9B-GGUF/resolve/main/flux-2-klein-9b-Q4_0.gguf
    sha256: "3d5e58acdf68308bddf325a6f7045c0c36a9bce6832bb8a59f5ce193ddf979f5"
    size: 5620000000
    format: gguf
    precision: q4_0
    vram_required: 8192
    vram_recommended: 10240
    note: "GGUF Q4_0."

  - id: gguf-q3-k-m
    file: flux-2-klein-9b-Q3_K_M.gguf
    url: https://huggingface.co/unsloth/FLUX.2-klein-9B-GGUF/resolve/main/flux-2-klein-9b-Q3_K_M.gguf
    sha256: "93ed5cf37c8dd0b379cfe4cd3feaa03683d8a56492a62baa5ecbbab232277573"
    size: 4770000000
    format: gguf
    precision: q3_k_m
    vram_required: 6144
    vram_recommended: 8192
    note: "GGUF Q3_K_M — for 8GB GPUs. Some quality loss."

  - id: gguf-q3-k-s
    file: flux-2-klein-9b-Q3_K_S.gguf
    url: https://huggingface.co/unsloth/FLUX.2-klein-9B-GGUF/resolve/main/flux-2-klein-9b-Q3_K_S.gguf
    sha256: "41f9255c4eda7abf6b06a50826a88e70090a523d0c65785487ae300e9f8d4362"
    size: 4690000000
    format: gguf
    precision: q3_k_s
    vram_required: 6144
    vram_recommended: 8192
    note: "GGUF Q3_K_S — smaller Q3 variant."

  - id: gguf-q2-k
    file: flux-2-klein-9b-Q2_K.gguf
    url: https://huggingface.co/unsloth/FLUX.2-klein-9B-GGUF/resolve/main/flux-2-klein-9b-Q2_K.gguf
    sha256: "0bcc795ca67361e53db3ceeceda02fd58bf117d20ee8cc30b257cc06f6a3027f"
    size: 3980000000
    format: gguf
    precision: q2_k
    vram_required: 6144
    vram_recommended: 8192
    note: "GGUF Q2_K — worst quality but smallest. Noticeable degradation."

requires:
  - id: flux2-vae
    type: vae
    reason: "FLUX.2 VAE for decoding latents to images"
  - id: flux2-qwen3-8b-text-encoder
    type: text_encoder
    reason: "Qwen 3 8B text encoder for prompt processing"

tags:
  - flux
  - text-to-image
  - image-editing
  - gguf
  - comfyui
  - unsloth

rating: 4.7
downloads: 0
added: "2025-07-01"
updated: "2025-07-01"

preview_images:
  - https://huggingface.co/unsloth/FLUX.2-klein-9B-GGUF/resolve/main/assets/flux2klein9b.png
