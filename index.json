{
  "version": 1,
  "items": [
    {
      "id": "4x-ultrasharp",
      "name": "4x UltraSharp Upscaler",
      "type": "upscaler",
      "author": "Kim2091",
      "license": "cc-by-nc-sa-4.0",
      "homepage": "https://openmodeldb.info/models/4x-UltraSharp",
      "description": "High-quality 4x upscaler. Excellent for photo-realistic upscaling.\nOne of the most popular upscalers in the AI image generation community.\n",
      "scale_factor": 4,
      "file": {
        "url": "https://huggingface.co/Kim2091/UltraSharp/resolve/main/4x-UltraSharp.pth",
        "sha256": "a5812231fc936b42af08a5edba784195495d303d5b3248c24489ef0c4021fe01",
        "size": 66921375,
        "format": "pth"
      },
      "tags": [
        "upscaler",
        "4x",
        "photo-realistic",
        "esrgan"
      ],
      "rating": 4.9,
      "downloads": 3200000,
      "added": "2023-01-01",
      "updated": "2024-01-01"
    },
    {
      "id": "birefnet-dis",
      "name": "BiRefNet DIS (Dichotomous Image Segmentation)",
      "type": "segmentation",
      "architecture": "birefnet",
      "author": "ViperYX",
      "license": "mit",
      "homepage": "https://huggingface.co/ViperYX/BiRefNet",
      "description": "High-quality background removal / image segmentation model.\nBiRefNet (Bilateral Reference Network) trained on DIS5K dataset for\ndichotomous image segmentation — excels at precise foreground/background separation.\nUsed in ComfyUI via ComfyUI_BiRefNet_ll custom node.\n",
      "file": {
        "url": "https://huggingface.co/ViperYX/BiRefNet/resolve/main/BiRefNet-DIS_ep580.pth",
        "sha256": "9b4510f31d72e41507a4b75c4e62206b1d7e2223e0125b29644acd4b142793b0",
        "size": 889192448,
        "format": "pth"
      },
      "tags": [
        "segmentation",
        "background-removal",
        "birefnet",
        "matting",
        "comfyui"
      ],
      "rating": 4.8,
      "downloads": 65000,
      "added": "2024-03-01",
      "updated": "2024-03-01"
    },
    {
      "id": "bsrganx2",
      "name": "BSRGANx2 Upscaler",
      "type": "upscaler",
      "author": "cszn",
      "license": "apache-2.0",
      "homepage": "https://github.com/cszn/BSRGAN",
      "description": "2x upscaler based on BSRGAN (Blind Super-Resolution GAN).\nBetter than bicubic for real-world degraded/noisy/compressed images.\nHandles JPEG artifacts, noise, and blur well — good for product photos\nthat have been through lossy compression.\n",
      "scale_factor": 2,
      "file": {
        "url": "https://huggingface.co/uwg/upscaler/resolve/main/ESRGAN/BSRGANx2.pth",
        "sha256": "eef929a6e8c39f68d8c921bd9d5fd2ae7202f32d982acf514e235a18f7f3d4f6",
        "size": 71849987,
        "format": "pth"
      },
      "tags": [
        "upscaler",
        "2x",
        "bsrgan",
        "denoising",
        "real-world",
        "esrgan"
      ],
      "rating": 4.6,
      "downloads": 450000,
      "added": "2022-01-01",
      "updated": "2022-01-01"
    },
    {
      "id": "clip-l",
      "name": "CLIP-L Text Encoder",
      "type": "text_encoder",
      "architecture": "clip",
      "author": "comfyanonymous",
      "license": "apache-2.0",
      "homepage": "https://huggingface.co/comfyanonymous/flux_text_encoders",
      "description": "CLIP-L (Large) text encoder. Used as secondary text encoder by FLUX models\nalongside T5-XXL. Small and lightweight — 246 MB.\n",
      "file": {
        "url": "https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/clip_l.safetensors",
        "sha256": "660c6f5b1abae9dc498ac2d21e1347d2abdb0cf6c0c0c8576cd796491d9a6cdd",
        "size": 246144152,
        "format": "safetensors"
      },
      "tags": [
        "clip",
        "text-encoder",
        "flux",
        "lightweight"
      ],
      "rating": 5.0,
      "downloads": 2600000,
      "added": "2024-08-01",
      "updated": "2024-08-01"
    },
    {
      "id": "flux-canny-dev",
      "name": "FLUX.1 Canny Dev",
      "type": "diffusion_model",
      "architecture": "flux",
      "author": "black-forest-labs",
      "license": "flux-1-dev-non-commercial-license",
      "homepage": "https://huggingface.co/black-forest-labs/FLUX.1-Canny-dev",
      "description": "FLUX.1 Canny Dev — canny edge conditioned generation model on FLUX architecture.\nStructural control via canny edge maps. Gated model.\n",
      "auth": {
        "provider": "huggingface",
        "gated": true,
        "terms_url": "https://huggingface.co/black-forest-labs/FLUX.1-Canny-dev"
      },
      "file": {
        "url": "https://huggingface.co/black-forest-labs/FLUX.1-Canny-dev/resolve/main/flux1-canny-dev.safetensors",
        "sha256": "996876670169591cb412b937fbd46ea14cbed6933aef17c48a2dcd9685c98cdb",
        "size": 23803351736,
        "format": "safetensors"
      },
      "requires": [
        {
          "id": "clip-l",
          "type": "text_encoder",
          "reason": "CLIP-L text encoder for FLUX"
        },
        {
          "id": "t5-xxl-fp8",
          "type": "text_encoder",
          "reason": "T5-XXL text encoder for FLUX"
        },
        {
          "id": "flux-vae",
          "type": "vae",
          "reason": "FLUX VAE"
        }
      ],
      "tags": [
        "flux",
        "controlnet",
        "canny",
        "edge-detection"
      ],
      "rating": 4.7,
      "downloads": 480000,
      "added": "2024-10-01",
      "updated": "2025-01-01"
    },
    {
      "id": "flux-depth-controlnet",
      "name": "FLUX.1 Depth ControlNet",
      "type": "controlnet",
      "architecture": "flux",
      "author": "InstantX",
      "license": "apache-2.0",
      "homepage": "https://huggingface.co/InstantX/FLUX.1-dev-Controlnet-Union",
      "description": "Depth-conditioned ControlNet for FLUX.1 Dev. Allows generating images\nthat follow the depth structure of an input image.\n",
      "base_models": [
        "flux-dev"
      ],
      "preprocessor": "depth_midas",
      "file": {
        "url": "https://huggingface.co/InstantX/FLUX.1-dev-Controlnet-Union/resolve/main/diffusion_pytorch_model.safetensors",
        "sha256": "0ec7deeff0e8d407744dbc96ce867b842ff11d51cc0c6132a3bd271091f041e1",
        "size": 6596901888,
        "format": "safetensors"
      },
      "tags": [
        "flux",
        "controlnet",
        "depth",
        "instantx"
      ],
      "rating": 4.5,
      "downloads": 380000,
      "added": "2024-10-01",
      "updated": "2025-01-01"
    },
    {
      "id": "flux-dev",
      "name": "FLUX.1 Dev",
      "type": "checkpoint",
      "architecture": "flux",
      "author": "black-forest-labs",
      "license": "flux-1-dev-non-commercial",
      "homepage": "https://huggingface.co/black-forest-labs/FLUX.1-dev",
      "description": "High-quality text-to-image model from Black Forest Labs.\nBest results with 20-30 steps, CFG 3.5-4.0, euler sampler.\nNon-commercial license. Requires accepting terms on HuggingFace.\n",
      "variants": [
        {
          "id": "fp16",
          "file": "flux1-dev.safetensors",
          "url": "https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/flux1-dev.safetensors",
          "sha256": "4610115bb0c89560703c892c59ac2742fa821e60ef5871b33493ba544683abd7",
          "size": 23802932552,
          "format": "safetensors",
          "precision": "fp16",
          "vram_required": 24576,
          "vram_recommended": 24576
        },
        {
          "id": "fp8",
          "file": "flux1-dev-fp8-e4m3fn.safetensors",
          "url": "https://huggingface.co/Kijai/flux-fp8/resolve/main/flux1-dev-fp8-e4m3fn.safetensors",
          "sha256": "e2c62660c9d75e928da6c0b9930993190f152f3c5c6f0cca69e77c21db87dd58",
          "size": 11903959040,
          "format": "safetensors",
          "precision": "fp8-e4m3fn",
          "vram_required": 12288,
          "vram_recommended": 16384,
          "note": "Quantized to fp8. Slight quality reduction vs fp16."
        }
      ],
      "requires": [
        {
          "id": "flux-vae",
          "type": "vae",
          "reason": "Flux models require the Flux-specific VAE (ae.safetensors)"
        },
        {
          "id": "t5-xxl-fp16",
          "type": "text_encoder",
          "reason": "T5-XXL for prompt processing",
          "optional_variant": "t5-xxl-fp8"
        },
        {
          "id": "clip-l",
          "type": "text_encoder",
          "reason": "CLIP-L for secondary text encoding"
        }
      ],
      "auth": {
        "provider": "huggingface",
        "terms_url": "https://huggingface.co/black-forest-labs/FLUX.1-dev",
        "gated": true
      },
      "defaults": {
        "steps": 20,
        "cfg": 3.5,
        "sampler": "euler",
        "scheduler": "normal"
      },
      "tags": [
        "flux",
        "text-to-image",
        "high-quality",
        "bfl"
      ],
      "rating": 4.9,
      "downloads": 2850000,
      "added": "2024-08-01",
      "updated": "2025-01-15",
      "preview_images": [
        "https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/poster.png"
      ]
    },
    {
      "id": "flux-fill-dev",
      "name": "FLUX.1 Fill Dev",
      "type": "diffusion_model",
      "architecture": "flux",
      "author": "black-forest-labs",
      "license": "flux-1-dev-non-commercial-license",
      "homepage": "https://huggingface.co/black-forest-labs/FLUX.1-Fill-dev",
      "description": "FLUX.1 Fill Dev — inpainting and outpainting model based on FLUX architecture.\nSupports masked image fill with text-guided generation. Gated model.\n",
      "auth": {
        "provider": "huggingface",
        "gated": true,
        "terms_url": "https://huggingface.co/black-forest-labs/FLUX.1-Fill-dev"
      },
      "file": {
        "url": "https://huggingface.co/black-forest-labs/FLUX.1-Fill-dev/resolve/main/flux1-fill-dev.safetensors",
        "sha256": "03e289f530df51d014f48e675a9ffa2141bc003259bf5f25d75b957e920a41ca",
        "size": 23804922408,
        "format": "safetensors"
      },
      "requires": [
        {
          "id": "clip-l",
          "type": "text_encoder",
          "reason": "CLIP-L text encoder for FLUX"
        },
        {
          "id": "t5-xxl-fp8",
          "type": "text_encoder",
          "reason": "T5-XXL text encoder for FLUX"
        },
        {
          "id": "flux-vae",
          "type": "vae",
          "reason": "FLUX VAE"
        }
      ],
      "tags": [
        "flux",
        "inpainting",
        "outpainting",
        "fill"
      ],
      "rating": 4.8,
      "downloads": 650000,
      "added": "2024-10-01",
      "updated": "2025-01-01"
    },
    {
      "id": "flux-redux-dev",
      "name": "FLUX.1 Redux Dev",
      "type": "ipadapter",
      "architecture": "flux",
      "author": "black-forest-labs",
      "license": "flux-1-dev-non-commercial-license",
      "homepage": "https://huggingface.co/black-forest-labs/FLUX.1-Redux-dev",
      "description": "FLUX.1 Redux Dev — image variation adapter for FLUX. Takes image input and\ngenerates variations, similar to IP-Adapter functionality. Gated model.\n",
      "auth": {
        "provider": "huggingface",
        "gated": true,
        "terms_url": "https://huggingface.co/black-forest-labs/FLUX.1-Redux-dev"
      },
      "file": {
        "url": "https://huggingface.co/black-forest-labs/FLUX.1-Redux-dev/resolve/main/flux1-redux-dev.safetensors",
        "sha256": "a1b3bdcb4bdc58ce04874b9ca776d61fc3e914bb6beab41efb63e4e2694dca45",
        "size": 129063232,
        "format": "safetensors"
      },
      "tags": [
        "flux",
        "ipadapter",
        "image-variation",
        "redux"
      ],
      "rating": 4.6,
      "downloads": 320000,
      "added": "2024-10-01",
      "updated": "2025-01-01"
    },
    {
      "id": "flux-schnell",
      "name": "FLUX.1 Schnell",
      "type": "checkpoint",
      "architecture": "flux",
      "author": "black-forest-labs",
      "license": "apache-2.0",
      "homepage": "https://huggingface.co/black-forest-labs/FLUX.1-schnell",
      "description": "Fast text-to-image model from Black Forest Labs.\nOptimized for speed — best with 1-4 steps, CFG 0 (distilled model).\nApache 2.0 license — free for commercial use.\n",
      "variants": [
        {
          "id": "fp16",
          "file": "flux1-schnell.safetensors",
          "url": "https://huggingface.co/black-forest-labs/FLUX.1-schnell/resolve/main/flux1-schnell.safetensors",
          "sha256": "9403429e0052277ac2a87ad800adece5481eecefd9ed334e1f348723621d2a0a",
          "size": 23782506688,
          "format": "safetensors",
          "precision": "fp16",
          "vram_required": 24576,
          "vram_recommended": 24576
        },
        {
          "id": "fp8",
          "file": "flux1-schnell-fp8-e4m3fn.safetensors",
          "url": "https://huggingface.co/Kijai/flux-fp8/resolve/main/flux1-schnell-fp8-e4m3fn.safetensors",
          "sha256": "722c8f4c3a7a57f7c08998ef273e142e2f4362e0de704bc5848fa8adfbbfb96c",
          "size": 11903959040,
          "format": "safetensors",
          "precision": "fp8-e4m3fn",
          "vram_required": 12288,
          "vram_recommended": 16384,
          "note": "Quantized to fp8. Slight quality reduction vs fp16."
        }
      ],
      "requires": [
        {
          "id": "flux-vae",
          "type": "vae",
          "reason": "Flux models require the Flux-specific VAE (ae.safetensors)"
        },
        {
          "id": "t5-xxl-fp16",
          "type": "text_encoder",
          "reason": "T5-XXL for prompt processing",
          "optional_variant": "t5-xxl-fp8"
        },
        {
          "id": "clip-l",
          "type": "text_encoder",
          "reason": "CLIP-L for secondary text encoding"
        }
      ],
      "auth": {
        "provider": "huggingface",
        "terms_url": "https://huggingface.co/black-forest-labs/FLUX.1-schnell",
        "gated": true
      },
      "defaults": {
        "steps": 4,
        "cfg": 0,
        "sampler": "euler",
        "scheduler": "normal"
      },
      "tags": [
        "flux",
        "text-to-image",
        "fast",
        "distilled",
        "bfl"
      ],
      "rating": 4.7,
      "downloads": 1920000,
      "added": "2024-08-01",
      "updated": "2025-01-15"
    },
    {
      "id": "flux-vae",
      "name": "FLUX VAE (ae.safetensors)",
      "type": "vae",
      "architecture": "flux",
      "author": "black-forest-labs",
      "license": "apache-2.0",
      "homepage": "https://huggingface.co/black-forest-labs/FLUX.1-schnell",
      "description": "The VAE used by all FLUX models. Required for FLUX.1 Dev and Schnell.\nSame file (ae.safetensors) is bundled in both the Dev and Schnell repos.\n",
      "file": {
        "url": "https://huggingface.co/black-forest-labs/FLUX.1-schnell/resolve/main/ae.safetensors",
        "sha256": "f5b59a26851551b67ae1fe58d32e76486e1e812def4696a4bea97f16604d40a3",
        "size": 335304388,
        "format": "safetensors"
      },
      "tags": [
        "flux",
        "vae",
        "bfl"
      ],
      "rating": 5.0,
      "downloads": 3200000,
      "added": "2024-08-01",
      "updated": "2024-08-01"
    },
    {
      "id": "flux2-dev",
      "name": "FLUX.2 Dev",
      "type": "diffusion_model",
      "architecture": "flux2",
      "author": "black-forest-labs / Comfy-Org",
      "license": "flux-2-dev-non-commercial",
      "homepage": "https://huggingface.co/Comfy-Org/flux2-dev",
      "description": "FLUX.2 Dev — next-generation image model from Black Forest Labs.\nUp to 4MP photorealistic output with improved lighting, skin, fabric, and hand detail.\nMulti-reference consistency (up to 10 images), improved editing precision,\nbetter visual understanding, and professional-class text rendering.\nUses Mistral 3 Small text encoder and FLUX.2 VAE.\nOpen-source (non-commercial license).\n",
      "variants": [
        {
          "id": "fp8mixed",
          "file": "flux2_dev_fp8mixed.safetensors",
          "url": "https://huggingface.co/Comfy-Org/flux2-dev/resolve/main/split_files/diffusion_models/flux2_dev_fp8mixed.safetensors",
          "sha256": "2f159bd5e5a9511d9470e23f303b5e44da33c6c7ee037f29777679178a3430ac",
          "size": 12000000000,
          "format": "safetensors",
          "precision": "fp8-mixed",
          "vram_required": 12288,
          "vram_recommended": 16384,
          "note": "fp8 mixed precision quantization from Comfy-Org."
        }
      ],
      "requires": [
        {
          "id": "flux2-vae",
          "type": "vae",
          "reason": "FLUX.2 VAE for decoding latents to images"
        },
        {
          "id": "flux2-mistral-text-encoder",
          "type": "text_encoder",
          "reason": "Mistral 3 Small text encoder for prompt processing"
        }
      ],
      "auth": {
        "provider": "huggingface",
        "terms_url": "https://huggingface.co/black-forest-labs/FLUX.2-dev",
        "gated": true
      },
      "defaults": {
        "steps": 20,
        "cfg": 3.5,
        "sampler": "euler",
        "scheduler": "normal"
      },
      "tags": [
        "flux2",
        "text-to-image",
        "high-quality",
        "photorealistic",
        "multi-reference",
        "bfl",
        "comfyui"
      ],
      "rating": 4.9,
      "downloads": 0,
      "added": "2025-07-01",
      "updated": "2025-07-01"
    },
    {
      "id": "flux2-klein-4b",
      "name": "FLUX.2 Klein 4B",
      "type": "diffusion_model",
      "architecture": "flux2",
      "author": "black-forest-labs / Comfy-Org",
      "license": "flux-2-klein-non-commercial",
      "homepage": "https://huggingface.co/Comfy-Org/flux2-klein-4B",
      "description": "FLUX.2 Klein 4B — the fastest model in the FLUX family.\nUnifies text-to-image and image editing in one compact architecture.\nTwo variants: Base (undistilled, best for fine-tuning) and Distilled (4-step, ~1.2s on 5090).\nOnly 8.4 GB VRAM for distilled variant. Supports style transforms, semantic edits,\nobject replacement/removal, multi-reference composition, and iterative edits.\n",
      "variants": [
        {
          "id": "distilled-fp8",
          "file": "flux-2-klein-4b-fp8.safetensors",
          "url": "https://huggingface.co/black-forest-labs/FLUX.2-klein-4b-fp8/resolve/main/flux-2-klein-4b-fp8.safetensors",
          "sha256": "15005cf50d1361f75c61f7d213d7969063e2aaea7523beefe5d1e085d173568d",
          "size": 4500000000,
          "format": "safetensors",
          "precision": "fp8",
          "vram_required": 8192,
          "vram_recommended": 10240,
          "note": "4-step distilled. ~1.2s on RTX 5090. Best for speed."
        },
        {
          "id": "base-fp8",
          "file": "flux-2-klein-base-4b-fp8.safetensors",
          "url": "https://huggingface.co/black-forest-labs/FLUX.2-klein-base-4b-fp8/resolve/main/flux-2-klein-base-4b-fp8.safetensors",
          "sha256": "14cf50adf6e3837c4454b79520a5c73a8977bce4a7bb210eeb910ce59acbb83d",
          "size": 4500000000,
          "format": "safetensors",
          "precision": "fp8",
          "vram_required": 10240,
          "vram_recommended": 12288,
          "note": "Undistilled base. Better for fine-tuning and maximum flexibility."
        }
      ],
      "requires": [
        {
          "id": "flux2-vae",
          "type": "vae",
          "reason": "FLUX.2 VAE for decoding latents to images"
        },
        {
          "id": "flux2-qwen3-4b-text-encoder",
          "type": "text_encoder",
          "reason": "Qwen 3 4B text encoder for prompt processing"
        }
      ],
      "auth": {
        "provider": "huggingface",
        "terms_url": "https://huggingface.co/black-forest-labs/FLUX.2-klein-4b-fp8",
        "gated": true
      },
      "defaults": {
        "steps": 4,
        "cfg": 1.0,
        "sampler": "euler",
        "scheduler": "simple"
      },
      "tags": [
        "flux2",
        "klein",
        "text-to-image",
        "image-editing",
        "fast-inference",
        "4b",
        "comfyui"
      ],
      "rating": 4.8,
      "downloads": 0,
      "added": "2025-07-01",
      "updated": "2025-07-01"
    },
    {
      "id": "flux2-klein-9b",
      "name": "FLUX.2 Klein 9B",
      "type": "diffusion_model",
      "architecture": "flux",
      "author": "unsloth / shimmyshimmer",
      "license": "flux-2-klein-non-commercial",
      "homepage": "https://huggingface.co/unsloth/FLUX.2-klein-9B-GGUF",
      "description": "FLUX.2 Klein 9B from Unsloth, available as GGUF quantizations.\nSuccessor to FLUX.1 with improved image quality and editing capabilities.\nSupports text-to-image and image editing workflows.\nUses FLUX.2 VAE and Qwen 3 8B text encoder.\nRequires ComfyUI-GGUF custom node for GGUF variants.\n",
      "variants": [
        {
          "id": "bf16",
          "file": "flux-2-klein-9b-BF16.gguf",
          "url": "https://huggingface.co/unsloth/FLUX.2-klein-9B-GGUF/resolve/main/flux-2-klein-9b-BF16.gguf",
          "sha256": "d4a80a1885c8b952d8f8d171ab3d1cac166ae7223d5ff4b5ee2d40932ce9fd58",
          "size": 18200000000,
          "format": "gguf",
          "precision": "bf16",
          "vram_required": 20480,
          "vram_recommended": 24576,
          "note": "Full precision bf16 GGUF. Best quality."
        },
        {
          "id": "f16",
          "file": "flux-2-klein-9b-F16.gguf",
          "url": "https://huggingface.co/unsloth/FLUX.2-klein-9B-GGUF/resolve/main/flux-2-klein-9b-F16.gguf",
          "sha256": "f82a83fd13542f3d6ac76e67e1fe60c08cdceddab856337f1b9ec534d9b5ca6f",
          "size": 18200000000,
          "format": "gguf",
          "precision": "f16",
          "vram_required": 20480,
          "vram_recommended": 24576,
          "note": "Full precision fp16 GGUF."
        },
        {
          "id": "gguf-q8-0",
          "file": "flux-2-klein-9b-Q8_0.gguf",
          "url": "https://huggingface.co/unsloth/FLUX.2-klein-9B-GGUF/resolve/main/flux-2-klein-9b-Q8_0.gguf",
          "sha256": "824b14b3d89f62779db9bcfe6af9084a52e1a3880e7ff93d50943969f9e25b27",
          "size": 9980000000,
          "format": "gguf",
          "precision": "q8_0",
          "vram_required": 12288,
          "vram_recommended": 16384,
          "note": "GGUF Q8_0 — highest quality quantization."
        },
        {
          "id": "gguf-q6-k",
          "file": "flux-2-klein-9b-Q6_K.gguf",
          "url": "https://huggingface.co/unsloth/FLUX.2-klein-9B-GGUF/resolve/main/flux-2-klein-9b-Q6_K.gguf",
          "sha256": "e19f643ba4b66ed5b779bc6283f0629363cabb0490cb06823cadb30a549eda5d",
          "size": 7870000000,
          "format": "gguf",
          "precision": "q6_k",
          "vram_required": 10240,
          "vram_recommended": 12288,
          "note": "GGUF Q6_K — very good quality/size balance."
        },
        {
          "id": "gguf-q5-k-m",
          "file": "flux-2-klein-9b-Q5_K_M.gguf",
          "url": "https://huggingface.co/unsloth/FLUX.2-klein-9B-GGUF/resolve/main/flux-2-klein-9b-Q5_K_M.gguf",
          "sha256": "bac097be5094c7c3fba993a1e57c6bb9cfc1dd0b33d608cc419311334aa4d015",
          "size": 7020000000,
          "format": "gguf",
          "precision": "q5_k_m",
          "vram_required": 8192,
          "vram_recommended": 12288,
          "note": "GGUF Q5_K_M — recommended for 12GB+ GPUs."
        },
        {
          "id": "gguf-q5-k-s",
          "file": "flux-2-klein-9b-Q5_K_S.gguf",
          "url": "https://huggingface.co/unsloth/FLUX.2-klein-9B-GGUF/resolve/main/flux-2-klein-9b-Q5_K_S.gguf",
          "sha256": "5cd600987443bafb0c04ccde87f5e7b083a8fcab26cdd8c8f2b331dde25cd010",
          "size": 6940000000,
          "format": "gguf",
          "precision": "q5_k_s",
          "vram_required": 8192,
          "vram_recommended": 12288,
          "note": "GGUF Q5_K_S — smaller Q5 variant."
        },
        {
          "id": "gguf-q4-k-m",
          "file": "flux-2-klein-9b-Q4_K_M.gguf",
          "url": "https://huggingface.co/unsloth/FLUX.2-klein-9B-GGUF/resolve/main/flux-2-klein-9b-Q4_K_M.gguf",
          "sha256": "262df1a3a98bc328911e03d4d0f5d7e3b1397477a2c485b24509b6d115259aef",
          "size": 5910000000,
          "format": "gguf",
          "precision": "q4_k_m",
          "vram_required": 8192,
          "vram_recommended": 10240,
          "note": "GGUF Q4_K_M — good for 8GB GPUs."
        },
        {
          "id": "gguf-q4-k-s",
          "file": "flux-2-klein-9b-Q4_K_S.gguf",
          "url": "https://huggingface.co/unsloth/FLUX.2-klein-9B-GGUF/resolve/main/flux-2-klein-9b-Q4_K_S.gguf",
          "sha256": "ee1c0373abb438f1fda472ac15775a0b538bf6f464ec978eaaf8a2a96a42cac3",
          "size": 5830000000,
          "format": "gguf",
          "precision": "q4_k_s",
          "vram_required": 8192,
          "vram_recommended": 10240,
          "note": "GGUF Q4_K_S — smaller Q4 variant."
        },
        {
          "id": "gguf-q4-1",
          "file": "flux-2-klein-9b-Q4_1.gguf",
          "url": "https://huggingface.co/unsloth/FLUX.2-klein-9B-GGUF/resolve/main/flux-2-klein-9b-Q4_1.gguf",
          "sha256": "96c219d318d3ef9000159a11a6098e46da30a03848fdd375b7dfa3fc84199895",
          "size": 6160000000,
          "format": "gguf",
          "precision": "q4_1",
          "vram_required": 8192,
          "vram_recommended": 10240,
          "note": "GGUF Q4_1."
        },
        {
          "id": "gguf-q4-0",
          "file": "flux-2-klein-9b-Q4_0.gguf",
          "url": "https://huggingface.co/unsloth/FLUX.2-klein-9B-GGUF/resolve/main/flux-2-klein-9b-Q4_0.gguf",
          "sha256": "3d5e58acdf68308bddf325a6f7045c0c36a9bce6832bb8a59f5ce193ddf979f5",
          "size": 5620000000,
          "format": "gguf",
          "precision": "q4_0",
          "vram_required": 8192,
          "vram_recommended": 10240,
          "note": "GGUF Q4_0."
        },
        {
          "id": "gguf-q3-k-m",
          "file": "flux-2-klein-9b-Q3_K_M.gguf",
          "url": "https://huggingface.co/unsloth/FLUX.2-klein-9B-GGUF/resolve/main/flux-2-klein-9b-Q3_K_M.gguf",
          "sha256": "93ed5cf37c8dd0b379cfe4cd3feaa03683d8a56492a62baa5ecbbab232277573",
          "size": 4770000000,
          "format": "gguf",
          "precision": "q3_k_m",
          "vram_required": 6144,
          "vram_recommended": 8192,
          "note": "GGUF Q3_K_M — for 8GB GPUs. Some quality loss."
        },
        {
          "id": "gguf-q3-k-s",
          "file": "flux-2-klein-9b-Q3_K_S.gguf",
          "url": "https://huggingface.co/unsloth/FLUX.2-klein-9B-GGUF/resolve/main/flux-2-klein-9b-Q3_K_S.gguf",
          "sha256": "41f9255c4eda7abf6b06a50826a88e70090a523d0c65785487ae300e9f8d4362",
          "size": 4690000000,
          "format": "gguf",
          "precision": "q3_k_s",
          "vram_required": 6144,
          "vram_recommended": 8192,
          "note": "GGUF Q3_K_S — smaller Q3 variant."
        },
        {
          "id": "gguf-q2-k",
          "file": "flux-2-klein-9b-Q2_K.gguf",
          "url": "https://huggingface.co/unsloth/FLUX.2-klein-9B-GGUF/resolve/main/flux-2-klein-9b-Q2_K.gguf",
          "sha256": "0bcc795ca67361e53db3ceeceda02fd58bf117d20ee8cc30b257cc06f6a3027f",
          "size": 3980000000,
          "format": "gguf",
          "precision": "q2_k",
          "vram_required": 6144,
          "vram_recommended": 8192,
          "note": "GGUF Q2_K — worst quality but smallest. Noticeable degradation."
        }
      ],
      "requires": [
        {
          "id": "flux2-vae",
          "type": "vae",
          "reason": "FLUX.2 VAE for decoding latents to images"
        },
        {
          "id": "flux2-qwen3-8b-text-encoder",
          "type": "text_encoder",
          "reason": "Qwen 3 8B text encoder for prompt processing"
        }
      ],
      "tags": [
        "flux",
        "text-to-image",
        "image-editing",
        "gguf",
        "comfyui",
        "unsloth"
      ],
      "rating": 4.7,
      "downloads": 0,
      "added": "2025-07-01",
      "updated": "2025-07-01",
      "preview_images": [
        "https://huggingface.co/unsloth/FLUX.2-klein-9B-GGUF/resolve/main/assets/flux2klein9b.png"
      ]
    },
    {
      "id": "flux2-mistral-text-encoder",
      "name": "FLUX.2 Mistral 3 Small Text Encoder",
      "type": "text_encoder",
      "architecture": "mistral",
      "author": "Comfy-Org",
      "license": "apache-2.0",
      "homepage": "https://huggingface.co/Comfy-Org/flux2-dev",
      "description": "Mistral 3 Small text encoder (bf16) for FLUX.2 Dev.\nRequired for FLUX.2 Dev text-to-image generation.\n",
      "file": {
        "url": "https://huggingface.co/Comfy-Org/flux2-dev/resolve/main/split_files/text_encoders/mistral_3_small_flux2_bf16.safetensors",
        "sha256": "a8711134ac2d06dd36b03914220ee54a43e7dd9a23eecbeca25107d78eed3382",
        "size": 24000000000,
        "format": "safetensors"
      },
      "tags": [
        "flux2",
        "text-encoder",
        "mistral",
        "dev"
      ],
      "rating": 5.0,
      "downloads": 0,
      "added": "2025-07-01",
      "updated": "2025-07-01"
    },
    {
      "id": "flux2-qwen3-4b-text-encoder",
      "name": "FLUX.2 Qwen 3 4B Text Encoder",
      "type": "text_encoder",
      "architecture": "qwen",
      "author": "Comfy-Org",
      "license": "apache-2.0",
      "homepage": "https://huggingface.co/Comfy-Org/flux2-klein-4B",
      "description": "Qwen 3 4B text encoder for FLUX.2 Klein 4B models.\nRequired for both base and distilled 4B variants.\n",
      "file": {
        "url": "https://huggingface.co/Comfy-Org/flux2-klein-4B/resolve/main/split_files/text_encoders/qwen_3_4b.safetensors",
        "sha256": "f459cd74b7868799ea82f97601a650afcedc399596dc262f302e3505761c9995",
        "size": 9800000000,
        "format": "safetensors"
      },
      "tags": [
        "flux2",
        "text-encoder",
        "qwen",
        "klein-4b"
      ],
      "rating": 5.0,
      "downloads": 0,
      "added": "2025-07-01",
      "updated": "2025-07-01"
    },
    {
      "id": "flux2-qwen3-8b-text-encoder",
      "name": "FLUX.2 Qwen 3 8B Text Encoder",
      "type": "text_encoder",
      "architecture": "qwen",
      "author": "Comfy-Org",
      "license": "apache-2.0",
      "homepage": "https://huggingface.co/Comfy-Org/flux2-klein-9B",
      "description": "Qwen 3 8B text encoder (fp8 mixed) for FLUX.2 Klein 9B models.\nRequired for both base and distilled 9B variants.\n",
      "file": {
        "url": "https://huggingface.co/Comfy-Org/flux2-klein-9B/resolve/main/split_files/text_encoders/qwen_3_8b_fp8mixed.safetensors",
        "sha256": "334d028c0191eb19d32a26f45a2e426d0a33284b33d5da5595f402c206419105",
        "size": 8500000000,
        "format": "safetensors"
      },
      "tags": [
        "flux2",
        "text-encoder",
        "qwen",
        "klein-9b",
        "fp8"
      ],
      "rating": 5.0,
      "downloads": 0,
      "added": "2025-07-01",
      "updated": "2025-07-01"
    },
    {
      "id": "flux2-vae",
      "name": "FLUX.2 VAE",
      "type": "vae",
      "architecture": "flux2",
      "author": "black-forest-labs / Comfy-Org",
      "license": "apache-2.0",
      "homepage": "https://huggingface.co/Comfy-Org/flux2-dev",
      "description": "VAE for all FLUX.2 models (Dev, Klein 4B, Klein 9B).\nDifferent from FLUX.1 VAE — do not mix them.\nShared across all FLUX.2 model variants.\n",
      "file": {
        "url": "https://huggingface.co/Comfy-Org/flux2-dev/resolve/main/split_files/vae/flux2-vae.safetensors",
        "sha256": "bb534d41e8e6f92dc8636b914489b7167aeb950418183ffc10768c573185683a",
        "size": 335000000,
        "format": "safetensors"
      },
      "tags": [
        "flux2",
        "vae",
        "bfl"
      ],
      "rating": 5.0,
      "downloads": 0,
      "added": "2025-07-01",
      "updated": "2025-07-01"
    },
    {
      "id": "ip-adapter-faceid-sdxl",
      "name": "IP-Adapter FaceID (SDXL)",
      "type": "ipadapter",
      "architecture": "sdxl",
      "author": "h94",
      "license": "apache-2.0",
      "homepage": "https://huggingface.co/h94/IP-Adapter-FaceID",
      "description": "IP-Adapter with InsightFace face ID embedding for SDXL.\nFace-consistent generation from reference photos. Requires companion LoRA.\n",
      "base_models": [
        "sdxl-base-1.0"
      ],
      "file": {
        "url": "https://huggingface.co/h94/IP-Adapter-FaceID/resolve/main/ip-adapter-faceid_sdxl.bin",
        "sha256": "b924b678ef4ca408577e51faa08a4d281e3411fca24cb84a080a3751d65ed697",
        "size": 1148846080,
        "format": "bin"
      },
      "tags": [
        "sdxl",
        "ipadapter",
        "faceid",
        "face-consistent",
        "insightface"
      ],
      "rating": 4.5,
      "downloads": 800000,
      "added": "2024-01-15",
      "updated": "2024-06-01"
    },
    {
      "id": "ip-adapter-sdxl",
      "name": "IP-Adapter SDXL (ViT-H)",
      "type": "ipadapter",
      "architecture": "sdxl",
      "author": "h94",
      "license": "apache-2.0",
      "homepage": "https://huggingface.co/h94/IP-Adapter",
      "description": "IP-Adapter for SDXL using ViT-H image encoder. Enables image-prompted\ngeneration by conditioning on reference images. Style transfer and composition.\n",
      "base_models": [
        "sdxl-base-1.0"
      ],
      "file": {
        "url": "https://huggingface.co/h94/IP-Adapter/resolve/main/sdxl_models/ip-adapter_sdxl_vit-h.safetensors",
        "sha256": "ebf05d918348aec7abb02a5e9ecef77e0aaea6914a5c4ea13f50d45eb1681831",
        "size": 731906048,
        "format": "safetensors"
      },
      "tags": [
        "sdxl",
        "ipadapter",
        "image-prompt",
        "style-transfer"
      ],
      "rating": 4.7,
      "downloads": 1200000,
      "added": "2023-08-20",
      "updated": "2024-06-01"
    },
    {
      "id": "lcm-lora-sd15",
      "name": "LCM LoRA (SD 1.5)",
      "type": "lora",
      "architecture": "sd15",
      "author": "latent-consistency",
      "license": "openrail++",
      "homepage": "https://huggingface.co/latent-consistency/lcm-lora-sdv1-5",
      "description": "Latent Consistency Model LoRA for SD 1.5. Enables fast 2-8 step inference\nvia distillation. Drop-in acceleration for any SD 1.5 model.\n",
      "base_models": [
        "sd-1.5"
      ],
      "file": {
        "url": "https://huggingface.co/latent-consistency/lcm-lora-sdv1-5/resolve/main/pytorch_lora_weights.safetensors",
        "sha256": "8f90d840e075ff588a58e22c6586e2ae9a6f7922996ee6649a7f01072333afe4",
        "size": 134217728,
        "format": "safetensors"
      },
      "tags": [
        "sd15",
        "lora",
        "lcm",
        "fast-inference",
        "distillation"
      ],
      "rating": 4.5,
      "downloads": 1800000,
      "added": "2023-10-06",
      "updated": "2024-06-01"
    },
    {
      "id": "lcm-lora-sdxl",
      "name": "LCM LoRA (SDXL)",
      "type": "lora",
      "architecture": "sdxl",
      "author": "latent-consistency",
      "license": "openrail++",
      "homepage": "https://huggingface.co/latent-consistency/lcm-lora-sdxl",
      "description": "Latent Consistency Model LoRA for SDXL. Enables fast 2-8 step inference\nvia distillation. Drop-in acceleration for any SDXL model.\n",
      "base_models": [
        "sdxl-base-1.0",
        "sdxl-turbo"
      ],
      "file": {
        "url": "https://huggingface.co/latent-consistency/lcm-lora-sdxl/resolve/main/pytorch_lora_weights.safetensors",
        "sha256": "a764e6859b6e04047cd761c08ff0cee96413a8e004c9f07707530cd776b19141",
        "size": 393854976,
        "format": "safetensors"
      },
      "tags": [
        "sdxl",
        "lora",
        "lcm",
        "fast-inference",
        "distillation"
      ],
      "rating": 4.6,
      "downloads": 2200000,
      "added": "2023-10-06",
      "updated": "2024-06-01"
    },
    {
      "id": "qwen-image-clip",
      "name": "Qwen 2.5 VL 7B Text Encoder",
      "type": "text_encoder",
      "architecture": "qwen-vl",
      "author": "Comfy-Org",
      "license": "apache-2.0",
      "homepage": "https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI",
      "description": "Qwen 2.5 Vision-Language 7B text/vision encoder for Qwen Image Edit.\nHandles prompt processing and image understanding for the Qwen Image editing pipeline.\nAvailable in full bf16 (16.6 GB) and fp8 quantized (9.4 GB) variants.\n",
      "variants": [
        {
          "id": "fp8",
          "file": "qwen_2.5_vl_7b_fp8_scaled.safetensors",
          "url": "https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/text_encoders/qwen_2.5_vl_7b_fp8_scaled.safetensors",
          "sha256": "cb5636d852a0ea6a9075ab1bef496c0db7aef13c02350571e388aea959c5c0b4",
          "size": 10071982080,
          "format": "safetensors",
          "precision": "fp8-e4m3fn",
          "vram_required": 10240,
          "vram_recommended": 12288,
          "note": "FP8 scaled quantization. Recommended — good quality at half the size."
        },
        {
          "id": "bf16",
          "file": "qwen_2.5_vl_7b.safetensors",
          "url": "https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/text_encoders/qwen_2.5_vl_7b.safetensors",
          "sha256": "7dc87a9c61db8168b119859940bce41cf3f737784e8c43d8e71a9f9720fa4051",
          "size": 17825792000,
          "format": "safetensors",
          "precision": "bf16",
          "vram_required": 16384,
          "vram_recommended": 20480,
          "note": "Full bf16 precision. Best quality, needs more VRAM."
        }
      ],
      "tags": [
        "qwen",
        "text-encoder",
        "vision-language",
        "clip",
        "comfyui"
      ],
      "rating": 4.8,
      "downloads": 275000,
      "added": "2025-07-01",
      "updated": "2025-07-01"
    },
    {
      "id": "qwen-image-edit",
      "name": "Qwen Image Edit",
      "type": "checkpoint",
      "architecture": "qwen-image",
      "author": "Comfy-Org / QuantStack",
      "license": "apache-2.0",
      "homepage": "https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI",
      "description": "AI-powered image editing model based on Qwen 2.5 VL architecture.\nSupports outpainting, format/ratio changes, AI scene generation, and in-place enhancement.\nBest with 8 steps using Lightning LoRA, euler sampler, CFG 1.0.\nAvailable as native safetensors (bf16/fp8) or GGUF quantizations (Q2_K through Q8_0).\n",
      "variants": [
        {
          "id": "bf16",
          "file": "qwen_image_bf16.safetensors",
          "url": "https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/diffusion_models/qwen_image_bf16.safetensors",
          "sha256": "106966bb02e7f08a19b56d74db2491793aeadc740c993bcdb7d0e9dcbc9d94ab",
          "size": 43927101440,
          "format": "safetensors",
          "precision": "bf16",
          "vram_required": 40960,
          "vram_recommended": 49152,
          "note": "Full precision bf16. Best quality, needs A100 40GB+ or similar."
        },
        {
          "id": "fp8-hq",
          "file": "qwen_image_fp8_hq.safetensors",
          "url": "https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/diffusion_models/qwen_image_fp8_hq.safetensors",
          "sha256": "83717dba9759964b678b82258fb775d713661743b37661c13dee4f256109dcac",
          "size": 24373903360,
          "format": "safetensors",
          "precision": "fp8-e4m3fn",
          "vram_required": 24576,
          "vram_recommended": 32768,
          "note": "High-quality fp8 quantization with sensitive layers in higher precision."
        },
        {
          "id": "fp8-mixed",
          "file": "qwen_image_fp8mixed.safetensors",
          "url": "https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/diffusion_models/qwen_image_fp8mixed.safetensors",
          "sha256": "c2e20d799a317959b2cc7f270bf174df801cbb0b2a00b5e4549ecf78220cf6fb",
          "size": 22011707392,
          "format": "safetensors",
          "precision": "fp8-e4m3fn",
          "vram_required": 24576,
          "vram_recommended": 24576,
          "note": "Mixed precision fp8 with comfy_quant layers. Sensitive layers kept in high precision."
        },
        {
          "id": "fp8",
          "file": "qwen_image_fp8_e4m3fn.safetensors",
          "url": "https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/diffusion_models/qwen_image_fp8_e4m3fn.safetensors",
          "sha256": "3c291b78a18ea30fc99c3301385ec9c7481a5102b8da5cf5449f725c5ff5ac5f",
          "size": 21902483456,
          "format": "safetensors",
          "precision": "fp8-e4m3fn",
          "vram_required": 20480,
          "vram_recommended": 24576,
          "note": "Standard fp8 quantization. Good balance of quality vs VRAM."
        },
        {
          "id": "nvfp4",
          "file": "qwen_image_nvfp4.safetensors",
          "url": "https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/diffusion_models/qwen_image_nvfp4.safetensors",
          "sha256": "e194b9c5c2aa18606532e5ffa92d91c5e3ad16dde382cd6801149398b9e3bc25",
          "size": 21260902400,
          "format": "safetensors",
          "precision": "nvfp4",
          "vram_required": 16384,
          "vram_recommended": 20480,
          "note": "NVIDIA fp4 quantization. Lower quality but fits on smaller GPUs."
        },
        {
          "id": "2512-bf16",
          "file": "qwen_image_2512_bf16.safetensors",
          "url": "https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/diffusion_models/qwen_image_2512_bf16.safetensors",
          "sha256": "3c27bbc92757da35e0963bc75c8635feeab41ee6adaae93d159c397d1b39cc98",
          "size": 43927101440,
          "format": "safetensors",
          "precision": "bf16",
          "vram_required": 40960,
          "vram_recommended": 49152,
          "note": "2512 revision, full bf16 precision."
        },
        {
          "id": "2512-fp8",
          "file": "qwen_image_2512_fp8_e4m3fn.safetensors",
          "url": "https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/diffusion_models/qwen_image_2512_fp8_e4m3fn.safetensors",
          "sha256": "f07f1483dc9b19752b6032576a82c94b6e6cce3e0cad77ae27e928b7072b1c05",
          "size": 21902483456,
          "format": "safetensors",
          "precision": "fp8-e4m3fn",
          "vram_required": 20480,
          "vram_recommended": 24576,
          "note": "2512 revision, fp8 quantized."
        },
        {
          "id": "gguf-q8-0",
          "file": "Qwen_Image_Edit-Q8_0.gguf",
          "url": "https://huggingface.co/QuantStack/Qwen-Image-Edit-GGUF/resolve/main/Qwen_Image_Edit-Q8_0.gguf",
          "sha256": "e875c08781c562182cdc64939aab70ccfae3c44d9484e3c3d9429bad8682cf71",
          "size": 23405215744,
          "format": "gguf",
          "precision": "q8_0",
          "vram_required": 24576,
          "vram_recommended": 32768,
          "note": "GGUF Q8_0 — best GGUF quality. Requires ComfyUI-GGUF custom node."
        },
        {
          "id": "gguf-q6-k",
          "file": "Qwen_Image_Edit-Q6_K.gguf",
          "url": "https://huggingface.co/QuantStack/Qwen-Image-Edit-GGUF/resolve/main/Qwen_Image_Edit-Q6_K.gguf",
          "sha256": "2a6952b23262b881dfb681791482f00cbd4dc2f59016e55c14a09d5c2a9cc8b2",
          "size": 18039808000,
          "format": "gguf",
          "precision": "q6_k",
          "vram_required": 20480,
          "vram_recommended": 24576,
          "note": "GGUF Q6_K — good quality/size balance."
        },
        {
          "id": "gguf-q5-k-m",
          "file": "Qwen_Image_Edit-Q5_K_M.gguf",
          "url": "https://huggingface.co/QuantStack/Qwen-Image-Edit-GGUF/resolve/main/Qwen_Image_Edit-Q5_K_M.gguf",
          "sha256": "b398a64e4334c2d8cae676ce64534a38d3ebdd3d0878b57071620485e56211ce",
          "size": 16000204800,
          "format": "gguf",
          "precision": "q5_k_m",
          "vram_required": 16384,
          "vram_recommended": 20480,
          "note": "GGUF Q5_K_M — recommended for 16GB+ GPUs."
        },
        {
          "id": "gguf-q5-k-s",
          "file": "Qwen_Image_Edit-Q5_K_S.gguf",
          "url": "https://huggingface.co/QuantStack/Qwen-Image-Edit-GGUF/resolve/main/Qwen_Image_Edit-Q5_K_S.gguf",
          "sha256": "286571d761951e43853a1cec129c741cc7f541fb70b203f4131c84cafd8585f0",
          "size": 15140249600,
          "format": "gguf",
          "precision": "q5_k_s",
          "vram_required": 16384,
          "vram_recommended": 20480,
          "note": "GGUF Q5_K_S — smaller Q5 variant."
        },
        {
          "id": "gguf-q5-0",
          "file": "Qwen_Image_Edit-Q5_0.gguf",
          "url": "https://huggingface.co/QuantStack/Qwen-Image-Edit-GGUF/resolve/main/Qwen_Image_Edit-Q5_0.gguf",
          "sha256": "a8ace3d71b9b8e87859b330923f2d40421116a4548ad5fff180fad730cb29352",
          "size": 15461882880,
          "format": "gguf",
          "precision": "q5_0",
          "vram_required": 16384,
          "vram_recommended": 20480,
          "note": "GGUF Q5_0."
        },
        {
          "id": "gguf-q5-1",
          "file": "Qwen_Image_Edit-Q5_1.gguf",
          "url": "https://huggingface.co/QuantStack/Qwen-Image-Edit-GGUF/resolve/main/Qwen_Image_Edit-Q5_1.gguf",
          "sha256": "4006179697444691f31e0fbb7a8beb6d373d1a0d6ff4f34a2e3efa5e8d9c0f85",
          "size": 16536027136,
          "format": "gguf",
          "precision": "q5_1",
          "vram_required": 16384,
          "vram_recommended": 20480,
          "note": "GGUF Q5_1."
        },
        {
          "id": "gguf-q4-k-m",
          "file": "Qwen_Image_Edit-Q4_K_M.gguf",
          "url": "https://huggingface.co/QuantStack/Qwen-Image-Edit-GGUF/resolve/main/Qwen_Image_Edit-Q4_K_M.gguf",
          "sha256": "bee346224c34ec00991aa1d75a0fd4c259c4ac375ad346edf4c3fff7ec30be1c",
          "size": 14066032640,
          "format": "gguf",
          "precision": "q4_k_m",
          "vram_required": 12288,
          "vram_recommended": 16384,
          "note": "GGUF Q4_K_M — good for 12GB GPUs."
        },
        {
          "id": "gguf-q4-k-s",
          "file": "Qwen_Image_Edit-Q4_K_S.gguf",
          "url": "https://huggingface.co/QuantStack/Qwen-Image-Edit-GGUF/resolve/main/Qwen_Image_Edit-Q4_K_S.gguf",
          "sha256": "44301250d40bfbe53c9d2b62028bab576c52605b471b1a11ea0f9f1036b19743",
          "size": 12994428928,
          "format": "gguf",
          "precision": "q4_k_s",
          "vram_required": 12288,
          "vram_recommended": 16384,
          "note": "GGUF Q4_K_S — smaller Q4 variant."
        },
        {
          "id": "gguf-q4-0",
          "file": "Qwen_Image_Edit-Q4_0.gguf",
          "url": "https://huggingface.co/QuantStack/Qwen-Image-Edit-GGUF/resolve/main/Qwen_Image_Edit-Q4_0.gguf",
          "sha256": "40d9298d5a7881afdf62e9bfa9581cbbe435fb2038448dde8f0a127a48c49fbb",
          "size": 12776923136,
          "format": "gguf",
          "precision": "q4_0",
          "vram_required": 12288,
          "vram_recommended": 16384,
          "note": "GGUF Q4_0."
        },
        {
          "id": "gguf-q4-1",
          "file": "Qwen_Image_Edit-Q4_1.gguf",
          "url": "https://huggingface.co/QuantStack/Qwen-Image-Edit-GGUF/resolve/main/Qwen_Image_Edit-Q4_1.gguf",
          "sha256": "55ed396b0ed764a5f237b87307ec0679e4d59b71e984ef61ea89d46457017eb5",
          "size": 13743095808,
          "format": "gguf",
          "precision": "q4_1",
          "vram_required": 12288,
          "vram_recommended": 16384,
          "note": "GGUF Q4_1."
        },
        {
          "id": "gguf-q3-k-m",
          "file": "Qwen_Image_Edit-Q3_K_M.gguf",
          "url": "https://huggingface.co/QuantStack/Qwen-Image-Edit-GGUF/resolve/main/Qwen_Image_Edit-Q3_K_M.gguf",
          "sha256": "056411f536e5b6ef6efa08d3c773911d9ec0945dbfce9be0f43c5519c525b3ee",
          "size": 10394116096,
          "format": "gguf",
          "precision": "q3_k_m",
          "vram_required": 10240,
          "vram_recommended": 12288,
          "note": "GGUF Q3_K_M — for 10GB+ GPUs. Noticeable quality reduction."
        },
        {
          "id": "gguf-q3-k-s",
          "file": "Qwen_Image_Edit-Q3_K_S.gguf",
          "url": "https://huggingface.co/QuantStack/Qwen-Image-Edit-GGUF/resolve/main/Qwen_Image_Edit-Q3_K_S.gguf",
          "sha256": "c2e82411c73d1cc98db87bfc640381eb211f9c28ba57e943e3fe71283cf97cf6",
          "size": 9609625600,
          "format": "gguf",
          "precision": "q3_k_s",
          "vram_required": 10240,
          "vram_recommended": 12288,
          "note": "GGUF Q3_K_S — smaller Q3 variant."
        },
        {
          "id": "gguf-q2-k",
          "file": "Qwen_Image_Edit-Q2_K.gguf",
          "url": "https://huggingface.co/QuantStack/Qwen-Image-Edit-GGUF/resolve/main/Qwen_Image_Edit-Q2_K.gguf",
          "sha256": "a449446a0fedad1949032f32f70ef5f8514e699ad0c3f27d8ab04b9f87b6d992",
          "size": 7580321792,
          "format": "gguf",
          "precision": "q2_k",
          "vram_required": 8192,
          "vram_recommended": 10240,
          "note": "GGUF Q2_K — minimum quality. Fits on 8GB GPUs but significant quality loss."
        }
      ],
      "requires": [
        {
          "id": "qwen-image-vae",
          "type": "vae",
          "reason": "Qwen Image Edit requires the Qwen-specific VAE"
        },
        {
          "id": "qwen-image-clip",
          "type": "text_encoder",
          "reason": "Qwen 2.5 VL 7B text/vision encoder for prompt processing"
        }
      ],
      "defaults": {
        "steps": 8,
        "cfg": 1.0,
        "sampler": "euler",
        "scheduler": "simple"
      },
      "tags": [
        "qwen",
        "image-editing",
        "outpainting",
        "scene-generation",
        "comfyui",
        "gguf"
      ],
      "rating": 4.8,
      "downloads": 275000,
      "added": "2025-07-01",
      "updated": "2026-01-15"
    },
    {
      "id": "qwen-image-edit-lightning",
      "name": "Qwen Image Edit Lightning LoRA",
      "type": "lora",
      "author": "lightx2v",
      "license": "apache-2.0",
      "homepage": "https://huggingface.co/lightx2v/Qwen-Image-Lightning",
      "description": "Distillation LoRA for Qwen Image Edit that reduces inference from ~50 steps to 4-8 steps.\nMultiple versions available: V1.0 and V2.0, in 4-step and 8-step variants.\nAlso includes Edit-specific variants for image editing (vs generation).\nbf16 variants are half the size (~850 MB) with no quality loss on bf16/fp8 base models.\n",
      "base_models": [
        "qwen-image-edit"
      ],
      "variants": [
        {
          "id": "edit-8step-v1",
          "file": "Qwen-Image-Edit-Lightning-8steps-V1.0.safetensors",
          "url": "https://huggingface.co/lightx2v/Qwen-Image-Lightning/resolve/main/Qwen-Image-Edit-Lightning-8steps-V1.0.safetensors",
          "sha256": "5910104f8922bd3fa359c675ba2a72681327f538cfa768eb33044055bd27a826",
          "size": 1825361920,
          "format": "safetensors",
          "precision": "fp32",
          "note": "Edit-specific, 8-step, V1.0. fp32 weights. Used by shopify-reframe-ai."
        },
        {
          "id": "edit-8step-v1-bf16",
          "file": "Qwen-Image-Edit-Lightning-8steps-V1.0-bf16.safetensors",
          "url": "https://huggingface.co/lightx2v/Qwen-Image-Lightning/resolve/main/Qwen-Image-Edit-Lightning-8steps-V1.0-bf16.safetensors",
          "sha256": "10b750b221b36c9d9f3a3d693f0489714a63b7ba84c45606de5c96ed367156d7",
          "size": 912680960,
          "format": "safetensors",
          "precision": "bf16",
          "note": "Edit-specific, 8-step, V1.0 in bf16. Half the size."
        },
        {
          "id": "edit-4step-v1",
          "file": "Qwen-Image-Edit-Lightning-4steps-V1.0.safetensors",
          "url": "https://huggingface.co/lightx2v/Qwen-Image-Lightning/resolve/main/Qwen-Image-Edit-Lightning-4steps-V1.0.safetensors",
          "sha256": "376a95559695f41bfa97349f6232e78193e05d404cc507c2cdfdaae58632bb4b",
          "size": 1825361920,
          "format": "safetensors",
          "precision": "fp32",
          "note": "Edit-specific, 4-step, V1.0. Fastest but slightly lower quality than 8-step."
        },
        {
          "id": "edit-4step-v1-bf16",
          "file": "Qwen-Image-Edit-Lightning-4steps-V1.0-bf16.safetensors",
          "url": "https://huggingface.co/lightx2v/Qwen-Image-Lightning/resolve/main/Qwen-Image-Edit-Lightning-4steps-V1.0-bf16.safetensors",
          "sha256": "d8132c32e7df906603dd6b072ff2fb0af88ab15ef0f3ac697a2011c8b47bbeb1",
          "size": 912680960,
          "format": "safetensors",
          "precision": "bf16",
          "note": "Edit-specific, 4-step, V1.0 in bf16."
        },
        {
          "id": "gen-8step-v2",
          "file": "Qwen-Image-Lightning-8steps-V2.0.safetensors",
          "url": "https://huggingface.co/lightx2v/Qwen-Image-Lightning/resolve/main/Qwen-Image-Lightning-8steps-V2.0.safetensors",
          "sha256": "47e96584c92ce971dc3e3db8626e065d2765924f29c637ccbdac79adc1d2c562",
          "size": 1825361920,
          "format": "safetensors",
          "precision": "fp32",
          "note": "Generation-focused, 8-step, V2.0. Latest version."
        },
        {
          "id": "gen-8step-v2-bf16",
          "file": "Qwen-Image-Lightning-8steps-V2.0-bf16.safetensors",
          "url": "https://huggingface.co/lightx2v/Qwen-Image-Lightning/resolve/main/Qwen-Image-Lightning-8steps-V2.0-bf16.safetensors",
          "sha256": "4d8ffbd8c5ddc8637cf7b1e1e987ffb58b9146b972d09ce2002f3f29cf6fc17d",
          "size": 912680960,
          "format": "safetensors",
          "precision": "bf16",
          "note": "Generation-focused, 8-step, V2.0 in bf16."
        },
        {
          "id": "gen-4step-v2",
          "file": "Qwen-Image-Lightning-4steps-V2.0.safetensors",
          "url": "https://huggingface.co/lightx2v/Qwen-Image-Lightning/resolve/main/Qwen-Image-Lightning-4steps-V2.0.safetensors",
          "sha256": "d06a178e7f47d4f6127284815bf93fc152f6c420a9c8ae370ec7d213f244a535",
          "size": 1825361920,
          "format": "safetensors",
          "precision": "fp32",
          "note": "Generation-focused, 4-step, V2.0. Fastest generation."
        },
        {
          "id": "gen-4step-v2-bf16",
          "file": "Qwen-Image-Lightning-4steps-V2.0-bf16.safetensors",
          "url": "https://huggingface.co/lightx2v/Qwen-Image-Lightning/resolve/main/Qwen-Image-Lightning-4steps-V2.0-bf16.safetensors",
          "sha256": "e8ca961a24c5dd7744eb0c8c2af152ce9b366f8cfabdaaca96d72acbca868f5d",
          "size": 912680960,
          "format": "safetensors",
          "precision": "bf16",
          "note": "Generation-focused, 4-step, V2.0 in bf16."
        },
        {
          "id": "fp8-gen-4step-v1-bf16",
          "file": "Qwen-Image-fp8-e4m3fn-Lightning-4steps-V1.0-bf16.safetensors",
          "url": "https://huggingface.co/lightx2v/Qwen-Image-Lightning/resolve/main/Qwen-Image-fp8-e4m3fn-Lightning-4steps-V1.0-bf16.safetensors",
          "sha256": "a900d5b842a25451fbdd14361cf730a0870f2df5221cbadee855ff3ac91a7bdc",
          "size": 912680960,
          "format": "safetensors",
          "precision": "bf16",
          "note": "Trained specifically for fp8 base model. 4-step, bf16."
        },
        {
          "id": "fp8-gen-4step-v1-fp32",
          "file": "Qwen-Image-fp8-e4m3fn-Lightning-4steps-V1.0-fp32.safetensors",
          "url": "https://huggingface.co/lightx2v/Qwen-Image-Lightning/resolve/main/Qwen-Image-fp8-e4m3fn-Lightning-4steps-V1.0-fp32.safetensors",
          "sha256": "acafb9d389bb2ec78d94276da4ff2897ecc7436bef283d81d041199a03a17e03",
          "size": 1825361920,
          "format": "safetensors",
          "precision": "fp32",
          "note": "Trained specifically for fp8 base model. 4-step, fp32."
        }
      ],
      "recommended_weight": 1.0,
      "weight_range": [
        0.8,
        1.0
      ],
      "tags": [
        "qwen",
        "lora",
        "lightning",
        "distillation",
        "fast-inference",
        "comfyui"
      ],
      "rating": 4.7,
      "downloads": 773000,
      "added": "2025-08-01",
      "updated": "2025-10-01"
    },
    {
      "id": "qwen-image-vae",
      "name": "Qwen Image VAE",
      "type": "vae",
      "architecture": "qwen-image",
      "author": "Comfy-Org",
      "license": "apache-2.0",
      "homepage": "https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI",
      "description": "VAE for the Qwen Image Edit pipeline. Single file, no variants.\nRequired by all Qwen Image Edit checkpoints.\n",
      "file": {
        "url": "https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/vae/qwen_image_vae.safetensors",
        "sha256": "a70580f0213e67967ee9c95f05bb400e8fb08307e017a924bf3441223e023d1f",
        "size": 266338304,
        "format": "safetensors"
      },
      "tags": [
        "qwen",
        "vae",
        "comfyui"
      ],
      "rating": 5.0,
      "downloads": 275000,
      "added": "2025-07-01",
      "updated": "2025-07-01"
    },
    {
      "id": "realesrgan-x4plus",
      "name": "RealESRGAN x4plus",
      "type": "upscaler",
      "author": "xinntao",
      "license": "bsd-3-clause",
      "homepage": "https://github.com/xinntao/Real-ESRGAN",
      "description": "General-purpose 4x upscaler from the Real-ESRGAN project.\nGood balance of quality and speed. Works well for both\nphotos and AI-generated images.\n",
      "scale_factor": 4,
      "file": {
        "url": "https://huggingface.co/ai-forever/Real-ESRGAN/resolve/main/RealESRGAN_x4.pth",
        "sha256": "aa00f09ad753d88576b21ed977e97d634976377031b178acc3b5b238df463400",
        "size": 67040989,
        "format": "pth"
      },
      "tags": [
        "upscaler",
        "4x",
        "realesrgan",
        "general-purpose"
      ],
      "rating": 4.7,
      "downloads": 4500000,
      "added": "2022-06-01",
      "updated": "2024-01-01"
    },
    {
      "id": "sd-1.5",
      "name": "Stable Diffusion 1.5",
      "type": "checkpoint",
      "architecture": "sd15",
      "author": "runwayml",
      "license": "creativeml-openrail-m",
      "homepage": "https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5",
      "description": "The original Stable Diffusion 1.5. Lightweight, fast, huge ecosystem\nof LoRAs, embeddings, and ControlNets. 512x512 native resolution.\n",
      "variants": [
        {
          "id": "fp16",
          "file": "v1-5-pruned-emaonly.safetensors",
          "url": "https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.safetensors",
          "sha256": "2ac63bfb6186057d88b65c3aa47ec90fd8d9aa3269164fc37fed1cb6f1a1efd0",
          "size": 4265146304,
          "format": "safetensors",
          "precision": "fp16",
          "vram_required": 4096,
          "vram_recommended": 8192
        }
      ],
      "requires": [
        {
          "id": "sd-vae-ft-mse",
          "type": "vae",
          "reason": "Recommended VAE for SD 1.5 (sharper outputs)"
        }
      ],
      "defaults": {
        "steps": 25,
        "cfg": 7.5,
        "sampler": "dpmpp_2m",
        "scheduler": "karras"
      },
      "tags": [
        "sd15",
        "text-to-image",
        "stable-diffusion",
        "lightweight"
      ],
      "rating": 4.3,
      "downloads": 12000000,
      "added": "2022-10-20",
      "updated": "2024-01-01",
      "preview_images": [
        "https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly-demo-images/image_01.png"
      ]
    },
    {
      "id": "sd-2.1",
      "name": "Stable Diffusion 2.1",
      "type": "checkpoint",
      "architecture": "sd21",
      "author": "stabilityai",
      "license": "openrail++",
      "homepage": "https://huggingface.co/stabilityai/stable-diffusion-2-1",
      "description": "Stable Diffusion 2.1, fine-tuned from SD 2.0 with improved aesthetics.\nGenerates at 768x768 resolution. Uses OpenCLIP ViT-H/14 text encoder.\n",
      "file": {
        "url": "https://huggingface.co/stabilityai/stable-diffusion-2-1/resolve/main/v2-1_768-ema-pruned.safetensors",
        "sha256": "ad2a33c361c1f593c4a1571e8b1f328c6b1c7b7d8d5eabe3cee16e241c1f3b50",
        "size": 5214865152,
        "format": "safetensors"
      },
      "defaults": {
        "steps": 30,
        "cfg": 7.5,
        "sampler": "dpmpp_2m",
        "scheduler": "karras"
      },
      "tags": [
        "sd21",
        "text-to-image",
        "stable-diffusion",
        "768"
      ],
      "rating": 4.4,
      "downloads": 3200000,
      "added": "2022-12-07",
      "updated": "2024-01-01"
    },
    {
      "id": "sd-vae-ft-mse",
      "name": "SD VAE ft-MSE",
      "type": "vae",
      "architecture": "sd15",
      "author": "stabilityai",
      "license": "creativeml-openrail-m",
      "homepage": "https://huggingface.co/stabilityai/sd-vae-ft-mse",
      "description": "Fine-tuned VAE for Stable Diffusion 1.5. Produces sharper, more\ndetailed outputs compared to the default VAE. MSE-optimized.\n",
      "file": {
        "url": "https://huggingface.co/stabilityai/sd-vae-ft-mse/resolve/main/diffusion_pytorch_model.safetensors",
        "sha256": "a1d993488569e928462932c8c38a0760b874d166399b14414135bd9c42df5815",
        "size": 334643276,
        "format": "safetensors"
      },
      "tags": [
        "sd15",
        "vae",
        "fine-tuned",
        "mse"
      ],
      "rating": 4.7,
      "downloads": 6800000,
      "added": "2023-01-01",
      "updated": "2024-01-01"
    },
    {
      "id": "sd15-controlnet-canny",
      "name": "ControlNet v1.1 Canny (SD 1.5)",
      "type": "controlnet",
      "architecture": "sd15",
      "author": "lllyasviel",
      "license": "openrail",
      "homepage": "https://huggingface.co/lllyasviel/ControlNet-v1-1",
      "description": "ControlNet v1.1 for SD 1.5 — Canny edge detection conditioned generation.\nProvides structural control using canny edge maps. The most popular ControlNet.\n",
      "base_models": [
        "sd-1.5"
      ],
      "preprocessor": "canny",
      "file": {
        "url": "https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_canny.pth",
        "sha256": "f99cfe4c70910e38e3fece9918a4979ed7d3dcf9b81cee293e1755363af5406a",
        "size": 1557135360,
        "format": "pth"
      },
      "tags": [
        "sd15",
        "controlnet",
        "canny",
        "edge-detection"
      ],
      "rating": 4.8,
      "downloads": 4200000,
      "added": "2023-04-14",
      "updated": "2024-01-01"
    },
    {
      "id": "sd15-controlnet-depth",
      "name": "ControlNet v1.1 Depth (SD 1.5)",
      "type": "controlnet",
      "architecture": "sd15",
      "author": "lllyasviel",
      "license": "openrail",
      "homepage": "https://huggingface.co/lllyasviel/ControlNet-v1-1",
      "description": "ControlNet v1.1 for SD 1.5 — Depth map conditioned generation.\nUses MiDaS depth estimation maps for structural control.\n",
      "base_models": [
        "sd-1.5"
      ],
      "preprocessor": "depth_midas",
      "file": {
        "url": "https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11f1p_sd15_depth.pth",
        "sha256": "c48b0e8e0e22db42b8c6532b75cae8e8e8e8e0e25c8e4c2b8e6b1c0a0e0e0e0",
        "size": 1557135360,
        "format": "pth"
      },
      "tags": [
        "sd15",
        "controlnet",
        "depth",
        "midas"
      ],
      "rating": 4.7,
      "downloads": 3500000,
      "added": "2023-04-14",
      "updated": "2024-01-01"
    },
    {
      "id": "sd15-controlnet-openpose",
      "name": "ControlNet v1.1 OpenPose (SD 1.5)",
      "type": "controlnet",
      "architecture": "sd15",
      "author": "lllyasviel",
      "license": "openrail",
      "homepage": "https://huggingface.co/lllyasviel/ControlNet-v1-1",
      "description": "ControlNet v1.1 for SD 1.5 — OpenPose body pose conditioned generation.\nUses human pose skeleton for structural control. Great for character posing.\n",
      "base_models": [
        "sd-1.5"
      ],
      "preprocessor": "openpose",
      "file": {
        "url": "https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_openpose.pth",
        "sha256": "8383832959b1e8b37660c5f236ab449c0d760a9df1db4c481cb881debf110d21",
        "size": 1557135360,
        "format": "pth"
      },
      "tags": [
        "sd15",
        "controlnet",
        "openpose",
        "pose"
      ],
      "rating": 4.7,
      "downloads": 3100000,
      "added": "2023-04-14",
      "updated": "2024-01-01"
    },
    {
      "id": "sdxl-base-1.0",
      "name": "Stable Diffusion XL Base 1.0",
      "type": "checkpoint",
      "architecture": "sdxl",
      "author": "stabilityai",
      "license": "openrail++",
      "homepage": "https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0",
      "description": "Stable Diffusion XL base model. High resolution text-to-image generation\nat 1024x1024. Works great with LoRAs and ControlNets.\n",
      "variants": [
        {
          "id": "fp16",
          "file": "sd_xl_base_1.0.safetensors",
          "url": "https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_base_1.0.safetensors",
          "sha256": "31e35c80fc4829d14f90153f4c74cd59c90b779f6afe05a74cd6120b893f7e5b",
          "size": 6938078334,
          "format": "safetensors",
          "precision": "fp16",
          "vram_required": 8192,
          "vram_recommended": 12288
        }
      ],
      "requires": [
        {
          "id": "sdxl-vae-fp16-fix",
          "type": "vae",
          "reason": "Recommended VAE for SDXL (fixes fp16 NaN issues)"
        }
      ],
      "defaults": {
        "steps": 30,
        "cfg": 7.0,
        "sampler": "dpmpp_2m",
        "scheduler": "karras"
      },
      "preview_images": [
        "https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/output.png"
      ],
      "tags": [
        "sdxl",
        "text-to-image",
        "stable-diffusion",
        "high-resolution"
      ],
      "rating": 4.6,
      "downloads": 5400000,
      "added": "2023-07-26",
      "updated": "2024-06-01"
    },
    {
      "id": "sdxl-controlnet-canny",
      "name": "ControlNet Canny (SDXL)",
      "type": "controlnet",
      "architecture": "sdxl",
      "author": "diffusers",
      "license": "openrail++",
      "homepage": "https://huggingface.co/diffusers/controlnet-canny-sdxl-1.0",
      "description": "ControlNet trained on SDXL for Canny edge detection conditioning.\nSingle-file diffusers-format model for structural control in SDXL.\n",
      "base_models": [
        "sdxl-base-1.0"
      ],
      "preprocessor": "canny",
      "variants": [
        {
          "id": "fp16",
          "file": "diffusion_pytorch_model.fp16.safetensors",
          "url": "https://huggingface.co/diffusers/controlnet-canny-sdxl-1.0/resolve/main/diffusion_pytorch_model.fp16.safetensors",
          "sha256": "b2e7d3921058a442cc80430d1ec8847f42599c705e2451c95e77cf4dcf8d6c25",
          "size": 2502139904,
          "format": "safetensors",
          "precision": "fp16",
          "vram_required": 8192
        },
        {
          "id": "fp32",
          "file": "diffusion_pytorch_model.safetensors",
          "url": "https://huggingface.co/diffusers/controlnet-canny-sdxl-1.0/resolve/main/diffusion_pytorch_model.safetensors",
          "sha256": "661481e7dbef1c09faa589c334b9d6d6595e2b7c85c77dbd8e0ec7f2a2ab2d75",
          "size": 5004279808,
          "format": "safetensors",
          "precision": "fp32",
          "vram_required": 16384
        }
      ],
      "tags": [
        "sdxl",
        "controlnet",
        "canny",
        "edge-detection"
      ],
      "rating": 4.6,
      "downloads": 1500000,
      "added": "2023-09-01",
      "updated": "2024-06-01"
    },
    {
      "id": "sdxl-refiner-1.0",
      "name": "SDXL Refiner 1.0",
      "type": "checkpoint",
      "architecture": "sdxl",
      "author": "stabilityai",
      "license": "openrail++",
      "homepage": "https://huggingface.co/stabilityai/stable-diffusion-xl-refiner-1.0",
      "description": "SDXL 1.0 Refiner — small-detail expert model. Used as a second pass\nto add fine details to images generated by SDXL Base.\n",
      "file": {
        "url": "https://huggingface.co/stabilityai/stable-diffusion-xl-refiner-1.0/resolve/main/sd_xl_refiner_1.0.safetensors",
        "sha256": "7440042bbdc8a24813002c09b6b69b64dc90fded4472613437b7f55f9b7d9c5f",
        "size": 6527995904,
        "format": "safetensors"
      },
      "requires": [
        {
          "id": "sdxl-vae-fp16-fix",
          "type": "vae",
          "reason": "Recommended VAE for SDXL"
        }
      ],
      "defaults": {
        "steps": 20,
        "cfg": 3.5,
        "sampler": "dpmpp_2m",
        "scheduler": "karras"
      },
      "tags": [
        "sdxl",
        "refiner",
        "detail",
        "stable-diffusion"
      ],
      "rating": 4.5,
      "downloads": 1800000,
      "added": "2023-07-26",
      "updated": "2024-06-01"
    },
    {
      "id": "sdxl-turbo",
      "name": "SDXL Turbo",
      "type": "checkpoint",
      "architecture": "sdxl",
      "author": "stabilityai",
      "license": "sai-nc-community",
      "homepage": "https://huggingface.co/stabilityai/sdxl-turbo",
      "description": "SDXL Turbo — distilled from SDXL 1.0 using Adversarial Diffusion Distillation.\nGenerates images in 1-4 steps at 512x512. Great for real-time applications.\n",
      "variants": [
        {
          "id": "fp16",
          "file": "sd_xl_turbo_1.0_fp16.safetensors",
          "url": "https://huggingface.co/stabilityai/sdxl-turbo/resolve/main/sd_xl_turbo_1.0_fp16.safetensors",
          "sha256": "e869ac7d6942cb327d68d5ed83a40447aadf20e0c3358d98b2cc9e270db0da26",
          "size": 6451034624,
          "format": "safetensors",
          "precision": "fp16",
          "vram_required": 6144,
          "vram_recommended": 8192
        },
        {
          "id": "fp32",
          "file": "sd_xl_turbo_1.0.safetensors",
          "url": "https://huggingface.co/stabilityai/sdxl-turbo/resolve/main/sd_xl_turbo_1.0.safetensors",
          "sha256": "d1bc2e4175e6ed0d0e8de98c42671384b8467b9bbdbcf558b4df66a427823d74",
          "size": 13902070784,
          "format": "safetensors",
          "precision": "fp32",
          "vram_required": 12288,
          "vram_recommended": 16384
        }
      ],
      "requires": [
        {
          "id": "sdxl-vae-fp16-fix",
          "type": "vae",
          "reason": "Recommended VAE for SDXL"
        }
      ],
      "defaults": {
        "steps": 1,
        "cfg": 0.0,
        "sampler": "euler_ancestral",
        "scheduler": "normal"
      },
      "tags": [
        "sdxl",
        "turbo",
        "fast",
        "text-to-image",
        "distilled"
      ],
      "rating": 4.7,
      "downloads": 2800000,
      "added": "2023-11-28",
      "updated": "2024-06-01"
    },
    {
      "id": "sdxl-vae-fp16-fix",
      "name": "SDXL VAE (fp16 NaN fix)",
      "type": "vae",
      "architecture": "sdxl",
      "author": "madebyollin",
      "license": "apache-2.0",
      "homepage": "https://huggingface.co/madebyollin/sdxl-vae-fp16-fix",
      "description": "Fixed SDXL VAE that works correctly in fp16 precision.\nThe original SDXL VAE produces NaN values in fp16 mode — this version\nfixes that issue. Recommended for all SDXL workflows.\n",
      "file": {
        "url": "https://huggingface.co/madebyollin/sdxl-vae-fp16-fix/resolve/main/diffusion_pytorch_model.safetensors",
        "sha256": "63aeecb90ff7bc1c115395962d3e803571385b61938377bc7089b36e81e92e2e",
        "size": 334643268,
        "format": "safetensors"
      },
      "tags": [
        "sdxl",
        "vae",
        "fp16-fix"
      ],
      "rating": 4.9,
      "downloads": 4100000,
      "added": "2023-08-15",
      "updated": "2024-01-01"
    },
    {
      "id": "t5-xxl-fp16",
      "name": "T5-XXL Text Encoder (fp16)",
      "type": "text_encoder",
      "architecture": "t5",
      "author": "comfyanonymous",
      "license": "apache-2.0",
      "homepage": "https://huggingface.co/comfyanonymous/flux_text_encoders",
      "description": "T5-XXL text encoder in fp16 precision. Required by FLUX models\nfor prompt processing. Large model — 9.8 GB.\nUse fp8 variant if you have less than 24 GB VRAM.\n",
      "variants": [
        {
          "id": "fp16",
          "file": "t5xxl_fp16.safetensors",
          "url": "https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/t5xxl_fp16.safetensors",
          "sha256": "eb88d1baeef3a46f6b723f62a69e91a116a34c60b0c0a32c9571d43551615213",
          "size": 9787849216,
          "format": "safetensors",
          "precision": "fp16",
          "vram_required": 12288,
          "vram_recommended": 16384
        }
      ],
      "tags": [
        "t5",
        "text-encoder",
        "flux",
        "fp16"
      ],
      "rating": 5.0,
      "downloads": 2400000,
      "added": "2024-08-01",
      "updated": "2024-08-01"
    },
    {
      "id": "t5-xxl-fp8",
      "name": "T5-XXL Text Encoder (fp8)",
      "type": "text_encoder",
      "architecture": "t5",
      "author": "comfyanonymous",
      "license": "apache-2.0",
      "homepage": "https://huggingface.co/comfyanonymous/flux_text_encoders",
      "description": "T5-XXL text encoder quantized to fp8 precision. Uses half the VRAM\nof the fp16 version with minimal quality impact.\nRecommended for 12-16 GB VRAM setups using FLUX models.\n",
      "variants": [
        {
          "id": "fp8",
          "file": "t5xxl_fp8_e4m3fn.safetensors",
          "url": "https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/t5xxl_fp8_e4m3fn.safetensors",
          "sha256": "7d330da4816157540d6bb7838bf63a0f02f573fc48ca4d8de34bb0cbfd514f09",
          "size": 4893843456,
          "format": "safetensors",
          "precision": "fp8-e4m3fn",
          "vram_required": 6144,
          "vram_recommended": 8192
        }
      ],
      "tags": [
        "t5",
        "text-encoder",
        "flux",
        "fp8",
        "quantized"
      ],
      "rating": 4.8,
      "downloads": 1800000,
      "added": "2024-08-01",
      "updated": "2024-08-01"
    },
    {
      "id": "z-image-text-encoder",
      "name": "Z-Image Qwen 3 4B Text Encoder",
      "type": "text_encoder",
      "architecture": "qwen3",
      "author": "Comfy-Org",
      "license": "apache-2.0",
      "homepage": "https://huggingface.co/Comfy-Org/z_image_turbo",
      "description": "Qwen 3 4B text encoder used by Z-Image-Turbo.\nAvailable in bf16 (full precision), fp8_mixed (reduced VRAM), and fp4_mixed (minimum VRAM).\nPlace in models/text_encoders/ and load with CLIPLoader node.\n",
      "variants": [
        {
          "id": "bf16",
          "file": "qwen_3_4b.safetensors",
          "url": "https://huggingface.co/Comfy-Org/z_image_turbo/resolve/main/split_files/text_encoders/qwen_3_4b.safetensors",
          "sha256": "6c671498573ac2f7a5501502ccce8d2b08ea6ca2f661c458e708f36b36edfc5a",
          "size": 8633139200,
          "format": "safetensors",
          "precision": "bf16",
          "vram_required": 10240,
          "vram_recommended": 12288,
          "note": "Full precision bf16. Best quality text encoding."
        },
        {
          "id": "fp8-mixed",
          "file": "qwen_3_4b_fp8_mixed.safetensors",
          "url": "https://huggingface.co/Comfy-Org/z_image_turbo/resolve/main/split_files/text_encoders/qwen_3_4b_fp8_mixed.safetensors",
          "sha256": "6cbe9dd2d57e7b59146d40aafeb6ed18d84c9f0e2169636109e56b55be6aadf6",
          "size": 6044237824,
          "format": "safetensors",
          "precision": "fp8-e4m3fn",
          "vram_required": 8192,
          "vram_recommended": 10240,
          "note": "Mixed fp8 quantization. Good quality with reduced VRAM."
        },
        {
          "id": "fp4-mixed",
          "file": "qwen_3_4b_fp4_mixed.safetensors",
          "url": "https://huggingface.co/Comfy-Org/z_image_turbo/resolve/main/split_files/text_encoders/qwen_3_4b_fp4_mixed.safetensors",
          "sha256": "fff344328a4fd638d3ab7a73f6cb4570ee9d269dab51e74a532d6267d5ed9ae3",
          "size": 3736076288,
          "format": "safetensors",
          "precision": "fp4",
          "vram_required": 4096,
          "vram_recommended": 6144,
          "note": "Mixed fp4 quantization. Minimum VRAM, some quality reduction."
        }
      ],
      "tags": [
        "z-image",
        "text-encoder",
        "qwen3",
        "comfyui"
      ],
      "rating": 4.8
    },
    {
      "id": "z-image-turbo",
      "name": "Z-Image-Turbo",
      "type": "diffusion_model",
      "architecture": "z-image",
      "author": "Tongyi-MAI / Comfy-Org / jayn7",
      "license": "apache-2.0",
      "homepage": "https://huggingface.co/Comfy-Org/z_image_turbo",
      "description": "Distilled 6B parameter text-to-image model from Alibaba Tongyi Lab.\nUses Scalable Single-Stream DiT (S3-DiT) architecture for maximum parameter efficiency.\nSub-second inference latency on H800 GPUs, fits within 16GB VRAM consumer devices.\nOnly 8 NFEs (steps) needed. Use euler sampler, guidance_scale 0.0.\nExcels at photorealistic generation and accurate bilingual text rendering (English & Chinese).\nAvailable as native safetensors (bf16/nvfp4) or GGUF quantizations.\n",
      "variants": [
        {
          "id": "bf16",
          "file": "z_image_turbo_bf16.safetensors",
          "url": "https://huggingface.co/Comfy-Org/z_image_turbo/resolve/main/split_files/diffusion_models/z_image_turbo_bf16.safetensors",
          "sha256": "2407613050b809ffdff18a4ac99af83ea6b95443ecebdf80e064a79c825574a6",
          "size": 13207024640,
          "format": "safetensors",
          "precision": "bf16",
          "vram_required": 16384,
          "vram_recommended": 24576,
          "note": "Full precision bf16. Best quality."
        },
        {
          "id": "nvfp4",
          "file": "z_image_turbo_nvfp4.safetensors",
          "url": "https://huggingface.co/Comfy-Org/z_image_turbo/resolve/main/split_files/diffusion_models/z_image_turbo_nvfp4.safetensors",
          "sha256": "6eabbfe5ae5a0c9b22cefffc83d5968f9f1ee77d68f32defe179ee7603e1470e",
          "size": 4843151360,
          "format": "safetensors",
          "precision": "nvfp4",
          "vram_required": 8192,
          "vram_recommended": 12288,
          "note": "NVIDIA fp4 quantization. Lower VRAM usage with minimal quality loss."
        },
        {
          "id": "gguf-q8-0",
          "file": "z_image_turbo-Q8_0.gguf",
          "url": "https://huggingface.co/jayn7/Z-Image-Turbo-GGUF/resolve/main/z_image_turbo-Q8_0.gguf",
          "sha256": "f163d60b0eb427469510b8226243d196574a18139a2e40c017409cfbda95ecfe",
          "size": 7755268096,
          "format": "gguf",
          "precision": "q8_0",
          "vram_required": 10240,
          "vram_recommended": 12288,
          "note": "GGUF Q8_0 — best GGUF quality. Requires ComfyUI-GGUF custom node."
        },
        {
          "id": "gguf-q6-k",
          "file": "z_image_turbo-Q6_K.gguf",
          "url": "https://huggingface.co/jayn7/Z-Image-Turbo-GGUF/resolve/main/z_image_turbo-Q6_K.gguf",
          "sha256": "fc137d87b49e06fdd5230d67d6c8cfa42a9e1fd38b65ccd355882450c3eb1c82",
          "size": 6346129408,
          "format": "gguf",
          "precision": "q6_k",
          "vram_required": 8192,
          "vram_recommended": 10240,
          "note": "GGUF Q6_K — good quality/size balance."
        },
        {
          "id": "gguf-q5-k-m",
          "file": "z_image_turbo-Q5_K_M.gguf",
          "url": "https://huggingface.co/jayn7/Z-Image-Turbo-GGUF/resolve/main/z_image_turbo-Q5_K_M.gguf",
          "sha256": "ea1b2f30b28fd52c73e631f0823494bf013f642d937e0ee1bdec4c1f1abc0103",
          "size": 5926789120,
          "format": "gguf",
          "precision": "q5_k_m",
          "vram_required": 8192,
          "vram_recommended": 10240,
          "note": "GGUF Q5_K_M — recommended for 8GB+ GPUs."
        },
        {
          "id": "gguf-q5-k-s",
          "file": "z_image_turbo-Q5_K_S.gguf",
          "url": "https://huggingface.co/jayn7/Z-Image-Turbo-GGUF/resolve/main/z_image_turbo-Q5_K_S.gguf",
          "sha256": "f00f7063d0d300cb9efbe82764edae2e956b34cd65220faa5f56cafff03065b5",
          "size": 5572034560,
          "format": "gguf",
          "precision": "q5_k_s",
          "vram_required": 8192,
          "vram_recommended": 10240,
          "note": "GGUF Q5_K_S — smaller Q5 variant."
        },
        {
          "id": "gguf-q4-k-m",
          "file": "z_image_turbo-Q4_K_M.gguf",
          "url": "https://huggingface.co/jayn7/Z-Image-Turbo-GGUF/resolve/main/z_image_turbo-Q4_K_M.gguf",
          "sha256": "8e2673db987bdc9248c336053ee773fb454eea3d3ef551b639f19812b6273503",
          "size": 5346283520,
          "format": "gguf",
          "precision": "q4_k_m",
          "vram_required": 6144,
          "vram_recommended": 8192,
          "note": "GGUF Q4_K_M — good for 8GB GPUs."
        },
        {
          "id": "gguf-q4-k-s",
          "file": "z_image_turbo-Q4_K_S.gguf",
          "url": "https://huggingface.co/jayn7/Z-Image-Turbo-GGUF/resolve/main/z_image_turbo-Q4_K_S.gguf",
          "sha256": "49cdba8a5db6ab01b8bed5fbb6796eacb83ed68cc2cc6f446d6bb0ec5fba982a",
          "size": 5003804672,
          "format": "gguf",
          "precision": "q4_k_s",
          "vram_required": 6144,
          "vram_recommended": 8192,
          "note": "GGUF Q4_K_S — smaller Q4 variant."
        },
        {
          "id": "gguf-q3-k-m",
          "file": "z_image_turbo-Q3_K_M.gguf",
          "url": "https://huggingface.co/jayn7/Z-Image-Turbo-GGUF/resolve/main/z_image_turbo-Q3_K_M.gguf",
          "sha256": "e660e8d66c1f41c8f2861d674a09492f64b97cd1c2c4e6ea0f39e9ceee02b969",
          "size": 4424990720,
          "format": "gguf",
          "precision": "q3_k_m",
          "vram_required": 6144,
          "vram_recommended": 8192,
          "note": "GGUF Q3_K_M — for 6GB+ GPUs. Noticeable quality reduction."
        },
        {
          "id": "gguf-q3-k-s",
          "file": "z_image_turbo-Q3_K_S.gguf",
          "url": "https://huggingface.co/jayn7/Z-Image-Turbo-GGUF/resolve/main/z_image_turbo-Q3_K_S.gguf",
          "sha256": "3d281cc0878d8a1f7184a63eef2ef13a0495bb9aaa25140886bf1068a13fc252",
          "size": 4069449728,
          "format": "gguf",
          "precision": "q3_k_s",
          "vram_required": 6144,
          "vram_recommended": 8192,
          "note": "GGUF Q3_K_S — smaller Q3 variant."
        }
      ],
      "requires": [
        {
          "id": "z-image-text-encoder",
          "type": "text_encoder",
          "reason": "Qwen 3 4B text encoder for prompt processing"
        },
        {
          "id": "z-image-vae",
          "type": "vae",
          "reason": "Z-Image VAE for decoding latents to images"
        }
      ],
      "recommended": {
        "steps": 8,
        "cfg": 0.0,
        "sampler": "euler",
        "scheduler": "simple"
      },
      "tags": [
        "z-image",
        "text-to-image",
        "turbo",
        "fast-inference",
        "bilingual",
        "comfyui",
        "gguf"
      ],
      "preview_images": [
        "https://huggingface.co/Comfy-Org/z_image_turbo/resolve/main/z_image_turbo_example.png"
      ],
      "rating": 4.9
    },
    {
      "id": "z-image-turbo-controlnet-union",
      "name": "Z-Image-Turbo Fun ControlNet Union",
      "type": "controlnet",
      "architecture": "z-image",
      "author": "alibaba-pai",
      "license": "apache-2.0",
      "homepage": "https://huggingface.co/alibaba-pai/Z-Image-Turbo-Fun-Controlnet-Union",
      "description": "ControlNet union model for Z-Image-Turbo.\nSupports Canny, HED, Depth, Pose, and MLSD control conditions.\nAdjust control_context_scale (0.65–0.80) for best results.\nUse with detailed prompts for better stability.\nV2.0 with inpaint mode also available separately.\n",
      "file": {
        "name": "Z-Image-Turbo-Fun-Controlnet-Union.safetensors",
        "url": "https://huggingface.co/alibaba-pai/Z-Image-Turbo-Fun-Controlnet-Union/resolve/main/Z-Image-Turbo-Fun-Controlnet-Union.safetensors",
        "sha256": "86c085c0d7853f12ce5183499934b54d08371c60f549c5a6b20615cd23989388",
        "size": 3328599040,
        "format": "safetensors"
      },
      "requires": [
        {
          "id": "z-image-turbo",
          "type": "diffusion_model",
          "reason": "Requires Z-Image-Turbo as the base diffusion model"
        }
      ],
      "tags": [
        "z-image",
        "controlnet",
        "canny",
        "depth",
        "pose",
        "comfyui"
      ],
      "rating": 4.6
    },
    {
      "id": "z-image-turbo-distill-lora",
      "name": "Z-Image-Turbo Distill Patch LoRA",
      "type": "lora",
      "architecture": "z-image",
      "author": "Comfy-Org",
      "license": "apache-2.0",
      "homepage": "https://huggingface.co/Comfy-Org/z_image_turbo",
      "description": "Distillation patch LoRA for Z-Image-Turbo.\nUsed to enable the base Z-Image model to run with fewer steps (turbo mode).\nApply via LoraLoader node with strength 1.0.\n",
      "file": {
        "name": "z_image_turbo_distill_patch_lora_bf16.safetensors",
        "url": "https://huggingface.co/Comfy-Org/z_image_turbo/resolve/main/split_files/loras/z_image_turbo_distill_patch_lora_bf16.safetensors",
        "sha256": "7247e6ad300373aacf1233d206223381727d9a9d19af1f2ff9db54ff1668a814",
        "size": 166723584,
        "format": "safetensors"
      },
      "tags": [
        "z-image",
        "lora",
        "distillation",
        "comfyui"
      ],
      "rating": 4.7
    },
    {
      "id": "z-image-vae",
      "name": "Z-Image VAE",
      "type": "vae",
      "architecture": "z-image",
      "author": "Comfy-Org",
      "license": "apache-2.0",
      "homepage": "https://huggingface.co/Comfy-Org/z_image_turbo",
      "description": "VAE for Z-Image-Turbo. Decodes latents to images.\nPlace in models/vae/ and load with VAELoader node.\n",
      "file": {
        "name": "z-image-vae.safetensors",
        "url": "https://huggingface.co/Comfy-Org/z_image_turbo/resolve/main/split_files/vae/ae.safetensors",
        "sha256": "afc8e28272cd15db3919bacdb6918ce9c1ed22e96cb12c4d5ed0fba823529e38",
        "size": 351272960,
        "format": "safetensors"
      },
      "tags": [
        "z-image",
        "vae",
        "comfyui"
      ],
      "rating": 5.0
    }
  ]
}