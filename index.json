{
  "version": 1,
  "items": [
    {
      "id": "4x-ultrasharp",
      "name": "4x UltraSharp Upscaler",
      "type": "upscaler",
      "author": "Kim2091",
      "license": "cc-by-nc-sa-4.0",
      "homepage": "https://openmodeldb.info/models/4x-UltraSharp",
      "description": "High-quality 4x upscaler. Excellent for photo-realistic upscaling.\nOne of the most popular upscalers in the AI image generation community.\n",
      "scale_factor": 4,
      "file": {
        "url": "https://huggingface.co/Kim2091/UltraSharp/resolve/main/4x-UltraSharp.pth",
        "sha256": "a5812231fc936b42af08a5edba784195495d303d5b3248c24489ef0c4021fe01",
        "size": 66921375,
        "format": "pth"
      },
      "tags": [
        "upscaler",
        "4x",
        "photo-realistic",
        "esrgan"
      ],
      "rating": 4.9,
      "downloads": 3200000,
      "added": "2023-01-01",
      "updated": "2024-01-01"
    },
    {
      "id": "birefnet-dis",
      "name": "BiRefNet DIS (Dichotomous Image Segmentation)",
      "type": "segmentation",
      "architecture": "birefnet",
      "author": "ViperYX",
      "license": "mit",
      "homepage": "https://huggingface.co/ViperYX/BiRefNet",
      "description": "High-quality background removal / image segmentation model.\nBiRefNet (Bilateral Reference Network) trained on DIS5K dataset for\ndichotomous image segmentation — excels at precise foreground/background separation.\nUsed in ComfyUI via ComfyUI_BiRefNet_ll custom node.\n",
      "file": {
        "url": "https://huggingface.co/ViperYX/BiRefNet/resolve/main/BiRefNet-DIS_ep580.pth",
        "sha256": "9b4510f31d72e41507a4b75c4e62206b1d7e2223e0125b29644acd4b142793b0",
        "size": 889192448,
        "format": "pth"
      },
      "tags": [
        "segmentation",
        "background-removal",
        "birefnet",
        "matting",
        "comfyui"
      ],
      "rating": 4.8,
      "downloads": 65000,
      "added": "2024-03-01",
      "updated": "2024-03-01"
    },
    {
      "id": "bsrganx2",
      "name": "BSRGANx2 Upscaler",
      "type": "upscaler",
      "author": "cszn",
      "license": "apache-2.0",
      "homepage": "https://github.com/cszn/BSRGAN",
      "description": "2x upscaler based on BSRGAN (Blind Super-Resolution GAN).\nBetter than bicubic for real-world degraded/noisy/compressed images.\nHandles JPEG artifacts, noise, and blur well — good for product photos\nthat have been through lossy compression.\n",
      "scale_factor": 2,
      "file": {
        "url": "https://huggingface.co/uwg/upscaler/resolve/main/ESRGAN/BSRGANx2.pth",
        "sha256": "VERIFY_bsrganx2",
        "size": 71849987,
        "format": "pth"
      },
      "tags": [
        "upscaler",
        "2x",
        "bsrgan",
        "denoising",
        "real-world",
        "esrgan"
      ],
      "rating": 4.6,
      "downloads": 450000,
      "added": "2022-01-01",
      "updated": "2022-01-01"
    },
    {
      "id": "clip-l",
      "name": "CLIP-L Text Encoder",
      "type": "text_encoder",
      "architecture": "clip",
      "author": "comfyanonymous",
      "license": "apache-2.0",
      "homepage": "https://huggingface.co/comfyanonymous/flux_text_encoders",
      "description": "CLIP-L (Large) text encoder. Used as secondary text encoder by FLUX models\nalongside T5-XXL. Small and lightweight — 246 MB.\n",
      "file": {
        "url": "https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/clip_l.safetensors",
        "sha256": "660c6f5b1abae9dc498ac2d21e1347d2abdb0cf6c0c0c8576cd796491d9a6cdd",
        "size": 246144152,
        "format": "safetensors"
      },
      "tags": [
        "clip",
        "text-encoder",
        "flux",
        "lightweight"
      ],
      "rating": 5.0,
      "downloads": 2600000,
      "added": "2024-08-01",
      "updated": "2024-08-01"
    },
    {
      "id": "flux-canny-dev",
      "name": "FLUX.1 Canny Dev",
      "type": "diffusion_model",
      "architecture": "flux",
      "author": "black-forest-labs",
      "license": "flux-1-dev-non-commercial-license",
      "homepage": "https://huggingface.co/black-forest-labs/FLUX.1-Canny-dev",
      "description": "FLUX.1 Canny Dev — canny edge conditioned generation model on FLUX architecture.\nStructural control via canny edge maps. Gated model.\n",
      "auth": {
        "provider": "huggingface",
        "gated": true,
        "terms_url": "https://huggingface.co/black-forest-labs/FLUX.1-Canny-dev"
      },
      "file": {
        "url": "https://huggingface.co/black-forest-labs/FLUX.1-Canny-dev/resolve/main/flux1-canny-dev.safetensors",
        "sha256": "VERIFY_flux_canny_dev",
        "size": 23800000000,
        "format": "safetensors"
      },
      "requires": [
        {
          "id": "clip-l",
          "type": "text_encoder",
          "reason": "CLIP-L text encoder for FLUX"
        },
        {
          "id": "t5-xxl-fp8",
          "type": "text_encoder",
          "reason": "T5-XXL text encoder for FLUX"
        },
        {
          "id": "flux-vae",
          "type": "vae",
          "reason": "FLUX VAE"
        }
      ],
      "tags": [
        "flux",
        "controlnet",
        "canny",
        "edge-detection"
      ],
      "rating": 4.7,
      "downloads": 480000,
      "added": "2024-10-01",
      "updated": "2025-01-01"
    },
    {
      "id": "flux-depth-controlnet",
      "name": "FLUX.1 Depth ControlNet",
      "type": "controlnet",
      "architecture": "flux",
      "author": "InstantX",
      "license": "apache-2.0",
      "homepage": "https://huggingface.co/InstantX/FLUX.1-dev-Controlnet-Union",
      "description": "Depth-conditioned ControlNet for FLUX.1 Dev. Allows generating images\nthat follow the depth structure of an input image.\n",
      "base_models": [
        "flux-dev"
      ],
      "preprocessor": "depth_midas",
      "file": {
        "url": "https://huggingface.co/InstantX/FLUX.1-dev-Controlnet-Union/resolve/main/diffusion_pytorch_model.safetensors",
        "sha256": "VERIFY_flux_depth_cn",
        "size": 6596901888,
        "format": "safetensors"
      },
      "tags": [
        "flux",
        "controlnet",
        "depth",
        "instantx"
      ],
      "rating": 4.5,
      "downloads": 380000,
      "added": "2024-10-01",
      "updated": "2025-01-01"
    },
    {
      "id": "flux-dev",
      "name": "FLUX.1 Dev",
      "type": "checkpoint",
      "architecture": "flux",
      "author": "black-forest-labs",
      "license": "flux-1-dev-non-commercial",
      "homepage": "https://huggingface.co/black-forest-labs/FLUX.1-dev",
      "description": "High-quality text-to-image model from Black Forest Labs.\nBest results with 20-30 steps, CFG 3.5-4.0, euler sampler.\nNon-commercial license. Requires accepting terms on HuggingFace.\n",
      "variants": [
        {
          "id": "fp16",
          "file": "flux1-dev.safetensors",
          "url": "https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/flux1-dev.safetensors",
          "sha256": "VERIFY_flux1_dev_fp16",
          "size": 23802932552,
          "format": "safetensors",
          "precision": "fp16",
          "vram_required": 24576,
          "vram_recommended": 24576
        },
        {
          "id": "fp8",
          "file": "flux1-dev-fp8-e4m3fn.safetensors",
          "url": "https://huggingface.co/Kijai/flux-fp8/resolve/main/flux1-dev-fp8-e4m3fn.safetensors",
          "sha256": "VERIFY_flux1_dev_fp8",
          "size": 11903959040,
          "format": "safetensors",
          "precision": "fp8-e4m3fn",
          "vram_required": 12288,
          "vram_recommended": 16384,
          "note": "Quantized to fp8. Slight quality reduction vs fp16."
        }
      ],
      "requires": [
        {
          "id": "flux-vae",
          "type": "vae",
          "reason": "Flux models require the Flux-specific VAE (ae.safetensors)"
        },
        {
          "id": "t5-xxl-fp16",
          "type": "text_encoder",
          "reason": "T5-XXL for prompt processing",
          "optional_variant": "t5-xxl-fp8"
        },
        {
          "id": "clip-l",
          "type": "text_encoder",
          "reason": "CLIP-L for secondary text encoding"
        }
      ],
      "auth": {
        "provider": "huggingface",
        "terms_url": "https://huggingface.co/black-forest-labs/FLUX.1-dev",
        "gated": true
      },
      "defaults": {
        "steps": 20,
        "cfg": 3.5,
        "sampler": "euler",
        "scheduler": "normal"
      },
      "tags": [
        "flux",
        "text-to-image",
        "high-quality",
        "bfl"
      ],
      "rating": 4.9,
      "downloads": 2850000,
      "added": "2024-08-01",
      "updated": "2025-01-15",
      "preview_images": [
        "https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/poster.png"
      ]
    },
    {
      "id": "flux-fill-dev",
      "name": "FLUX.1 Fill Dev",
      "type": "diffusion_model",
      "architecture": "flux",
      "author": "black-forest-labs",
      "license": "flux-1-dev-non-commercial-license",
      "homepage": "https://huggingface.co/black-forest-labs/FLUX.1-Fill-dev",
      "description": "FLUX.1 Fill Dev — inpainting and outpainting model based on FLUX architecture.\nSupports masked image fill with text-guided generation. Gated model.\n",
      "auth": {
        "provider": "huggingface",
        "gated": true,
        "terms_url": "https://huggingface.co/black-forest-labs/FLUX.1-Fill-dev"
      },
      "file": {
        "url": "https://huggingface.co/black-forest-labs/FLUX.1-Fill-dev/resolve/main/flux1-fill-dev.safetensors",
        "sha256": "VERIFY_flux_fill_dev",
        "size": 23800000000,
        "format": "safetensors"
      },
      "requires": [
        {
          "id": "clip-l",
          "type": "text_encoder",
          "reason": "CLIP-L text encoder for FLUX"
        },
        {
          "id": "t5-xxl-fp8",
          "type": "text_encoder",
          "reason": "T5-XXL text encoder for FLUX"
        },
        {
          "id": "flux-vae",
          "type": "vae",
          "reason": "FLUX VAE"
        }
      ],
      "tags": [
        "flux",
        "inpainting",
        "outpainting",
        "fill"
      ],
      "rating": 4.8,
      "downloads": 650000,
      "added": "2024-10-01",
      "updated": "2025-01-01"
    },
    {
      "id": "flux-redux-dev",
      "name": "FLUX.1 Redux Dev",
      "type": "ipadapter",
      "architecture": "flux",
      "author": "black-forest-labs",
      "license": "flux-1-dev-non-commercial-license",
      "homepage": "https://huggingface.co/black-forest-labs/FLUX.1-Redux-dev",
      "description": "FLUX.1 Redux Dev — image variation adapter for FLUX. Takes image input and\ngenerates variations, similar to IP-Adapter functionality. Gated model.\n",
      "auth": {
        "provider": "huggingface",
        "gated": true,
        "terms_url": "https://huggingface.co/black-forest-labs/FLUX.1-Redux-dev"
      },
      "file": {
        "url": "https://huggingface.co/black-forest-labs/FLUX.1-Redux-dev/resolve/main/flux1-redux-dev.safetensors",
        "sha256": "VERIFY_flux_redux_dev",
        "size": 135266304,
        "format": "safetensors"
      },
      "tags": [
        "flux",
        "ipadapter",
        "image-variation",
        "redux"
      ],
      "rating": 4.6,
      "downloads": 320000,
      "added": "2024-10-01",
      "updated": "2025-01-01"
    },
    {
      "id": "flux-schnell",
      "name": "FLUX.1 Schnell",
      "type": "checkpoint",
      "architecture": "flux",
      "author": "black-forest-labs",
      "license": "apache-2.0",
      "homepage": "https://huggingface.co/black-forest-labs/FLUX.1-schnell",
      "description": "Fast text-to-image model from Black Forest Labs.\nOptimized for speed — best with 1-4 steps, CFG 0 (distilled model).\nApache 2.0 license — free for commercial use.\n",
      "variants": [
        {
          "id": "fp16",
          "file": "flux1-schnell.safetensors",
          "url": "https://huggingface.co/black-forest-labs/FLUX.1-schnell/resolve/main/flux1-schnell.safetensors",
          "sha256": "VERIFY_flux1_schnell_fp16",
          "size": 23802932552,
          "format": "safetensors",
          "precision": "fp16",
          "vram_required": 24576,
          "vram_recommended": 24576
        },
        {
          "id": "fp8",
          "file": "flux1-schnell-fp8-e4m3fn.safetensors",
          "url": "https://huggingface.co/Kijai/flux-fp8/resolve/main/flux1-schnell-fp8-e4m3fn.safetensors",
          "sha256": "VERIFY_flux1_schnell_fp8",
          "size": 11903959040,
          "format": "safetensors",
          "precision": "fp8-e4m3fn",
          "vram_required": 12288,
          "vram_recommended": 16384,
          "note": "Quantized to fp8. Slight quality reduction vs fp16."
        }
      ],
      "requires": [
        {
          "id": "flux-vae",
          "type": "vae",
          "reason": "Flux models require the Flux-specific VAE (ae.safetensors)"
        },
        {
          "id": "t5-xxl-fp16",
          "type": "text_encoder",
          "reason": "T5-XXL for prompt processing",
          "optional_variant": "t5-xxl-fp8"
        },
        {
          "id": "clip-l",
          "type": "text_encoder",
          "reason": "CLIP-L for secondary text encoding"
        }
      ],
      "auth": {
        "provider": "huggingface",
        "terms_url": "https://huggingface.co/black-forest-labs/FLUX.1-schnell",
        "gated": true
      },
      "defaults": {
        "steps": 4,
        "cfg": 0,
        "sampler": "euler",
        "scheduler": "normal"
      },
      "tags": [
        "flux",
        "text-to-image",
        "fast",
        "distilled",
        "bfl"
      ],
      "rating": 4.7,
      "downloads": 1920000,
      "added": "2024-08-01",
      "updated": "2025-01-15"
    },
    {
      "id": "flux-vae",
      "name": "FLUX VAE (ae.safetensors)",
      "type": "vae",
      "architecture": "flux",
      "author": "black-forest-labs",
      "license": "apache-2.0",
      "homepage": "https://huggingface.co/black-forest-labs/FLUX.1-schnell",
      "description": "The VAE used by all FLUX models. Required for FLUX.1 Dev and Schnell.\nSame file (ae.safetensors) is bundled in both the Dev and Schnell repos.\n",
      "file": {
        "url": "https://huggingface.co/black-forest-labs/FLUX.1-schnell/resolve/main/ae.safetensors",
        "sha256": "f5b59a26851551b67ae1fe58d32e76486e1e812def4696a4bea97f16604d40a3",
        "size": 335304388,
        "format": "safetensors"
      },
      "tags": [
        "flux",
        "vae",
        "bfl"
      ],
      "rating": 5.0,
      "downloads": 3200000,
      "added": "2024-08-01",
      "updated": "2024-08-01"
    },
    {
      "id": "ip-adapter-faceid-sdxl",
      "name": "IP-Adapter FaceID (SDXL)",
      "type": "ipadapter",
      "architecture": "sdxl",
      "author": "h94",
      "license": "apache-2.0",
      "homepage": "https://huggingface.co/h94/IP-Adapter-FaceID",
      "description": "IP-Adapter with InsightFace face ID embedding for SDXL.\nFace-consistent generation from reference photos. Requires companion LoRA.\n",
      "base_models": [
        "sdxl-base-1.0"
      ],
      "file": {
        "url": "https://huggingface.co/h94/IP-Adapter-FaceID/resolve/main/ip-adapter-faceid_sdxl.bin",
        "sha256": "VERIFY_ip_adapter_faceid_sdxl",
        "size": 1148846080,
        "format": "bin"
      },
      "tags": [
        "sdxl",
        "ipadapter",
        "faceid",
        "face-consistent",
        "insightface"
      ],
      "rating": 4.5,
      "downloads": 800000,
      "added": "2024-01-15",
      "updated": "2024-06-01"
    },
    {
      "id": "ip-adapter-sdxl",
      "name": "IP-Adapter SDXL (ViT-H)",
      "type": "ipadapter",
      "architecture": "sdxl",
      "author": "h94",
      "license": "apache-2.0",
      "homepage": "https://huggingface.co/h94/IP-Adapter",
      "description": "IP-Adapter for SDXL using ViT-H image encoder. Enables image-prompted\ngeneration by conditioning on reference images. Style transfer and composition.\n",
      "base_models": [
        "sdxl-base-1.0"
      ],
      "file": {
        "url": "https://huggingface.co/h94/IP-Adapter/resolve/main/sdxl_models/ip-adapter_sdxl_vit-h.safetensors",
        "sha256": "ebf05d918348aec7abb02a5e9ecef77e0aaea6914a5c4ea13f50d45eb1681831",
        "size": 731906048,
        "format": "safetensors"
      },
      "tags": [
        "sdxl",
        "ipadapter",
        "image-prompt",
        "style-transfer"
      ],
      "rating": 4.7,
      "downloads": 1200000,
      "added": "2023-08-20",
      "updated": "2024-06-01"
    },
    {
      "id": "lcm-lora-sd15",
      "name": "LCM LoRA (SD 1.5)",
      "type": "lora",
      "architecture": "sd15",
      "author": "latent-consistency",
      "license": "openrail++",
      "homepage": "https://huggingface.co/latent-consistency/lcm-lora-sdv1-5",
      "description": "Latent Consistency Model LoRA for SD 1.5. Enables fast 2-8 step inference\nvia distillation. Drop-in acceleration for any SD 1.5 model.\n",
      "base_models": [
        "sd-1.5"
      ],
      "file": {
        "url": "https://huggingface.co/latent-consistency/lcm-lora-sdv1-5/resolve/main/pytorch_lora_weights.safetensors",
        "sha256": "8f90d840e075ff588a58e22c6586e2ae9a6f7922996ee6649a7f01072333afe4",
        "size": 134217728,
        "format": "safetensors"
      },
      "tags": [
        "sd15",
        "lora",
        "lcm",
        "fast-inference",
        "distillation"
      ],
      "rating": 4.5,
      "downloads": 1800000,
      "added": "2023-10-06",
      "updated": "2024-06-01"
    },
    {
      "id": "lcm-lora-sdxl",
      "name": "LCM LoRA (SDXL)",
      "type": "lora",
      "architecture": "sdxl",
      "author": "latent-consistency",
      "license": "openrail++",
      "homepage": "https://huggingface.co/latent-consistency/lcm-lora-sdxl",
      "description": "Latent Consistency Model LoRA for SDXL. Enables fast 2-8 step inference\nvia distillation. Drop-in acceleration for any SDXL model.\n",
      "base_models": [
        "sdxl-base-1.0",
        "sdxl-turbo"
      ],
      "file": {
        "url": "https://huggingface.co/latent-consistency/lcm-lora-sdxl/resolve/main/pytorch_lora_weights.safetensors",
        "sha256": "a764e6859b6e04047cd761c08ff0cee96413a8e004c9f07707530cd776b19141",
        "size": 393854976,
        "format": "safetensors"
      },
      "tags": [
        "sdxl",
        "lora",
        "lcm",
        "fast-inference",
        "distillation"
      ],
      "rating": 4.6,
      "downloads": 2200000,
      "added": "2023-10-06",
      "updated": "2024-06-01"
    },
    {
      "id": "qwen-image-clip",
      "name": "Qwen 2.5 VL 7B Text Encoder",
      "type": "text_encoder",
      "architecture": "qwen-vl",
      "author": "Comfy-Org",
      "license": "apache-2.0",
      "homepage": "https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI",
      "description": "Qwen 2.5 Vision-Language 7B text/vision encoder for Qwen Image Edit.\nHandles prompt processing and image understanding for the Qwen Image editing pipeline.\nAvailable in full bf16 (16.6 GB) and fp8 quantized (9.4 GB) variants.\n",
      "variants": [
        {
          "id": "fp8",
          "file": "qwen_2.5_vl_7b_fp8_scaled.safetensors",
          "url": "https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/text_encoders/qwen_2.5_vl_7b_fp8_scaled.safetensors",
          "sha256": "cb5636d852a0ea6a9075ab1bef496c0db7aef13c02350571e388aea959c5c0b4",
          "size": 10071982080,
          "format": "safetensors",
          "precision": "fp8-e4m3fn",
          "vram_required": 10240,
          "vram_recommended": 12288,
          "note": "FP8 scaled quantization. Recommended — good quality at half the size."
        },
        {
          "id": "bf16",
          "file": "qwen_2.5_vl_7b.safetensors",
          "url": "https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/text_encoders/qwen_2.5_vl_7b.safetensors",
          "sha256": "VERIFY_qwen_clip_bf16",
          "size": 17825792000,
          "format": "safetensors",
          "precision": "bf16",
          "vram_required": 16384,
          "vram_recommended": 20480,
          "note": "Full bf16 precision. Best quality, needs more VRAM."
        }
      ],
      "tags": [
        "qwen",
        "text-encoder",
        "vision-language",
        "clip",
        "comfyui"
      ],
      "rating": 4.8,
      "downloads": 275000,
      "added": "2025-07-01",
      "updated": "2025-07-01"
    },
    {
      "id": "qwen-image-edit",
      "name": "Qwen Image Edit",
      "type": "checkpoint",
      "architecture": "qwen-image",
      "author": "Comfy-Org / QuantStack",
      "license": "apache-2.0",
      "homepage": "https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI",
      "description": "AI-powered image editing model based on Qwen 2.5 VL architecture.\nSupports outpainting, format/ratio changes, AI scene generation, and in-place enhancement.\nBest with 8 steps using Lightning LoRA, euler sampler, CFG 1.0.\nAvailable as native safetensors (bf16/fp8) or GGUF quantizations (Q2_K through Q8_0).\n",
      "variants": [
        {
          "id": "bf16",
          "file": "qwen_image_bf16.safetensors",
          "url": "https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/diffusion_models/qwen_image_bf16.safetensors",
          "sha256": "VERIFY_qwen_image_bf16",
          "size": 43927101440,
          "format": "safetensors",
          "precision": "bf16",
          "vram_required": 40960,
          "vram_recommended": 49152,
          "note": "Full precision bf16. Best quality, needs A100 40GB+ or similar."
        },
        {
          "id": "fp8-hq",
          "file": "qwen_image_fp8_hq.safetensors",
          "url": "https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/diffusion_models/qwen_image_fp8_hq.safetensors",
          "sha256": "VERIFY_qwen_image_fp8_hq",
          "size": 24373903360,
          "format": "safetensors",
          "precision": "fp8-e4m3fn",
          "vram_required": 24576,
          "vram_recommended": 32768,
          "note": "High-quality fp8 quantization with sensitive layers in higher precision."
        },
        {
          "id": "fp8-mixed",
          "file": "qwen_image_fp8mixed.safetensors",
          "url": "https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/diffusion_models/qwen_image_fp8mixed.safetensors",
          "sha256": "VERIFY_qwen_image_fp8mixed",
          "size": 22011707392,
          "format": "safetensors",
          "precision": "fp8-e4m3fn",
          "vram_required": 24576,
          "vram_recommended": 24576,
          "note": "Mixed precision fp8 with comfy_quant layers. Sensitive layers kept in high precision."
        },
        {
          "id": "fp8",
          "file": "qwen_image_fp8_e4m3fn.safetensors",
          "url": "https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/diffusion_models/qwen_image_fp8_e4m3fn.safetensors",
          "sha256": "VERIFY_qwen_image_fp8",
          "size": 21902483456,
          "format": "safetensors",
          "precision": "fp8-e4m3fn",
          "vram_required": 20480,
          "vram_recommended": 24576,
          "note": "Standard fp8 quantization. Good balance of quality vs VRAM."
        },
        {
          "id": "nvfp4",
          "file": "qwen_image_nvfp4.safetensors",
          "url": "https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/diffusion_models/qwen_image_nvfp4.safetensors",
          "sha256": "VERIFY_qwen_image_nvfp4",
          "size": 21260902400,
          "format": "safetensors",
          "precision": "nvfp4",
          "vram_required": 16384,
          "vram_recommended": 20480,
          "note": "NVIDIA fp4 quantization. Lower quality but fits on smaller GPUs."
        },
        {
          "id": "2512-bf16",
          "file": "qwen_image_2512_bf16.safetensors",
          "url": "https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/diffusion_models/qwen_image_2512_bf16.safetensors",
          "sha256": "VERIFY_qwen_image_2512_bf16",
          "size": 43927101440,
          "format": "safetensors",
          "precision": "bf16",
          "vram_required": 40960,
          "vram_recommended": 49152,
          "note": "2512 revision, full bf16 precision."
        },
        {
          "id": "2512-fp8",
          "file": "qwen_image_2512_fp8_e4m3fn.safetensors",
          "url": "https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/diffusion_models/qwen_image_2512_fp8_e4m3fn.safetensors",
          "sha256": "VERIFY_qwen_image_2512_fp8",
          "size": 21902483456,
          "format": "safetensors",
          "precision": "fp8-e4m3fn",
          "vram_required": 20480,
          "vram_recommended": 24576,
          "note": "2512 revision, fp8 quantized."
        },
        {
          "id": "gguf-q8-0",
          "file": "Qwen_Image_Edit-Q8_0.gguf",
          "url": "https://huggingface.co/QuantStack/Qwen-Image-Edit-GGUF/resolve/main/Qwen_Image_Edit-Q8_0.gguf",
          "sha256": "VERIFY_qwen_gguf_q8_0",
          "size": 23405215744,
          "format": "gguf",
          "precision": "q8_0",
          "vram_required": 24576,
          "vram_recommended": 32768,
          "note": "GGUF Q8_0 — best GGUF quality. Requires ComfyUI-GGUF custom node."
        },
        {
          "id": "gguf-q6-k",
          "file": "Qwen_Image_Edit-Q6_K.gguf",
          "url": "https://huggingface.co/QuantStack/Qwen-Image-Edit-GGUF/resolve/main/Qwen_Image_Edit-Q6_K.gguf",
          "sha256": "VERIFY_qwen_gguf_q6_k",
          "size": 18039808000,
          "format": "gguf",
          "precision": "q6_k",
          "vram_required": 20480,
          "vram_recommended": 24576,
          "note": "GGUF Q6_K — good quality/size balance."
        },
        {
          "id": "gguf-q5-k-m",
          "file": "Qwen_Image_Edit-Q5_K_M.gguf",
          "url": "https://huggingface.co/QuantStack/Qwen-Image-Edit-GGUF/resolve/main/Qwen_Image_Edit-Q5_K_M.gguf",
          "sha256": "VERIFY_qwen_gguf_q5_k_m",
          "size": 16000204800,
          "format": "gguf",
          "precision": "q5_k_m",
          "vram_required": 16384,
          "vram_recommended": 20480,
          "note": "GGUF Q5_K_M — recommended for 16GB+ GPUs."
        },
        {
          "id": "gguf-q5-k-s",
          "file": "Qwen_Image_Edit-Q5_K_S.gguf",
          "url": "https://huggingface.co/QuantStack/Qwen-Image-Edit-GGUF/resolve/main/Qwen_Image_Edit-Q5_K_S.gguf",
          "sha256": "VERIFY_qwen_gguf_q5_k_s",
          "size": 15140249600,
          "format": "gguf",
          "precision": "q5_k_s",
          "vram_required": 16384,
          "vram_recommended": 20480,
          "note": "GGUF Q5_K_S — smaller Q5 variant."
        },
        {
          "id": "gguf-q5-0",
          "file": "Qwen_Image_Edit-Q5_0.gguf",
          "url": "https://huggingface.co/QuantStack/Qwen-Image-Edit-GGUF/resolve/main/Qwen_Image_Edit-Q5_0.gguf",
          "sha256": "VERIFY_qwen_gguf_q5_0",
          "size": 15461882880,
          "format": "gguf",
          "precision": "q5_0",
          "vram_required": 16384,
          "vram_recommended": 20480,
          "note": "GGUF Q5_0."
        },
        {
          "id": "gguf-q5-1",
          "file": "Qwen_Image_Edit-Q5_1.gguf",
          "url": "https://huggingface.co/QuantStack/Qwen-Image-Edit-GGUF/resolve/main/Qwen_Image_Edit-Q5_1.gguf",
          "sha256": "VERIFY_qwen_gguf_q5_1",
          "size": 16536027136,
          "format": "gguf",
          "precision": "q5_1",
          "vram_required": 16384,
          "vram_recommended": 20480,
          "note": "GGUF Q5_1."
        },
        {
          "id": "gguf-q4-k-m",
          "file": "Qwen_Image_Edit-Q4_K_M.gguf",
          "url": "https://huggingface.co/QuantStack/Qwen-Image-Edit-GGUF/resolve/main/Qwen_Image_Edit-Q4_K_M.gguf",
          "sha256": "VERIFY_qwen_gguf_q4_k_m",
          "size": 14066032640,
          "format": "gguf",
          "precision": "q4_k_m",
          "vram_required": 12288,
          "vram_recommended": 16384,
          "note": "GGUF Q4_K_M — good for 12GB GPUs."
        },
        {
          "id": "gguf-q4-k-s",
          "file": "Qwen_Image_Edit-Q4_K_S.gguf",
          "url": "https://huggingface.co/QuantStack/Qwen-Image-Edit-GGUF/resolve/main/Qwen_Image_Edit-Q4_K_S.gguf",
          "sha256": "VERIFY_qwen_gguf_q4_k_s",
          "size": 12994428928,
          "format": "gguf",
          "precision": "q4_k_s",
          "vram_required": 12288,
          "vram_recommended": 16384,
          "note": "GGUF Q4_K_S — smaller Q4 variant."
        },
        {
          "id": "gguf-q4-0",
          "file": "Qwen_Image_Edit-Q4_0.gguf",
          "url": "https://huggingface.co/QuantStack/Qwen-Image-Edit-GGUF/resolve/main/Qwen_Image_Edit-Q4_0.gguf",
          "sha256": "VERIFY_qwen_gguf_q4_0",
          "size": 12776923136,
          "format": "gguf",
          "precision": "q4_0",
          "vram_required": 12288,
          "vram_recommended": 16384,
          "note": "GGUF Q4_0."
        },
        {
          "id": "gguf-q4-1",
          "file": "Qwen_Image_Edit-Q4_1.gguf",
          "url": "https://huggingface.co/QuantStack/Qwen-Image-Edit-GGUF/resolve/main/Qwen_Image_Edit-Q4_1.gguf",
          "sha256": "VERIFY_qwen_gguf_q4_1",
          "size": 13743095808,
          "format": "gguf",
          "precision": "q4_1",
          "vram_required": 12288,
          "vram_recommended": 16384,
          "note": "GGUF Q4_1."
        },
        {
          "id": "gguf-q3-k-m",
          "file": "Qwen_Image_Edit-Q3_K_M.gguf",
          "url": "https://huggingface.co/QuantStack/Qwen-Image-Edit-GGUF/resolve/main/Qwen_Image_Edit-Q3_K_M.gguf",
          "sha256": "VERIFY_qwen_gguf_q3_k_m",
          "size": 10394116096,
          "format": "gguf",
          "precision": "q3_k_m",
          "vram_required": 10240,
          "vram_recommended": 12288,
          "note": "GGUF Q3_K_M — for 10GB+ GPUs. Noticeable quality reduction."
        },
        {
          "id": "gguf-q3-k-s",
          "file": "Qwen_Image_Edit-Q3_K_S.gguf",
          "url": "https://huggingface.co/QuantStack/Qwen-Image-Edit-GGUF/resolve/main/Qwen_Image_Edit-Q3_K_S.gguf",
          "sha256": "VERIFY_qwen_gguf_q3_k_s",
          "size": 9609625600,
          "format": "gguf",
          "precision": "q3_k_s",
          "vram_required": 10240,
          "vram_recommended": 12288,
          "note": "GGUF Q3_K_S — smaller Q3 variant."
        },
        {
          "id": "gguf-q2-k",
          "file": "Qwen_Image_Edit-Q2_K.gguf",
          "url": "https://huggingface.co/QuantStack/Qwen-Image-Edit-GGUF/resolve/main/Qwen_Image_Edit-Q2_K.gguf",
          "sha256": "VERIFY_qwen_gguf_q2_k",
          "size": 7580321792,
          "format": "gguf",
          "precision": "q2_k",
          "vram_required": 8192,
          "vram_recommended": 10240,
          "note": "GGUF Q2_K — minimum quality. Fits on 8GB GPUs but significant quality loss."
        }
      ],
      "requires": [
        {
          "id": "qwen-image-vae",
          "type": "vae",
          "reason": "Qwen Image Edit requires the Qwen-specific VAE"
        },
        {
          "id": "qwen-image-clip",
          "type": "text_encoder",
          "reason": "Qwen 2.5 VL 7B text/vision encoder for prompt processing"
        }
      ],
      "defaults": {
        "steps": 8,
        "cfg": 1.0,
        "sampler": "euler",
        "scheduler": "simple"
      },
      "tags": [
        "qwen",
        "image-editing",
        "outpainting",
        "scene-generation",
        "comfyui",
        "gguf"
      ],
      "rating": 4.8,
      "downloads": 275000,
      "added": "2025-07-01",
      "updated": "2026-01-15"
    },
    {
      "id": "qwen-image-edit-lightning",
      "name": "Qwen Image Edit Lightning LoRA",
      "type": "lora",
      "author": "lightx2v",
      "license": "apache-2.0",
      "homepage": "https://huggingface.co/lightx2v/Qwen-Image-Lightning",
      "description": "Distillation LoRA for Qwen Image Edit that reduces inference from ~50 steps to 4-8 steps.\nMultiple versions available: V1.0 and V2.0, in 4-step and 8-step variants.\nAlso includes Edit-specific variants for image editing (vs generation).\nbf16 variants are half the size (~850 MB) with no quality loss on bf16/fp8 base models.\n",
      "base_models": [
        "qwen-image-edit"
      ],
      "variants": [
        {
          "id": "edit-8step-v1",
          "file": "Qwen-Image-Edit-Lightning-8steps-V1.0.safetensors",
          "url": "https://huggingface.co/lightx2v/Qwen-Image-Lightning/resolve/main/Qwen-Image-Edit-Lightning-8steps-V1.0.safetensors",
          "sha256": "5910104f8922bd3fa359c675ba2a72681327f538cfa768eb33044055bd27a826",
          "size": 1825361920,
          "format": "safetensors",
          "precision": "fp32",
          "note": "Edit-specific, 8-step, V1.0. fp32 weights. Used by shopify-reframe-ai."
        },
        {
          "id": "edit-8step-v1-bf16",
          "file": "Qwen-Image-Edit-Lightning-8steps-V1.0-bf16.safetensors",
          "url": "https://huggingface.co/lightx2v/Qwen-Image-Lightning/resolve/main/Qwen-Image-Edit-Lightning-8steps-V1.0-bf16.safetensors",
          "sha256": "VERIFY_qwen_lightning_edit_8s_v1_bf16",
          "size": 912680960,
          "format": "safetensors",
          "precision": "bf16",
          "note": "Edit-specific, 8-step, V1.0 in bf16. Half the size."
        },
        {
          "id": "edit-4step-v1",
          "file": "Qwen-Image-Edit-Lightning-4steps-V1.0.safetensors",
          "url": "https://huggingface.co/lightx2v/Qwen-Image-Lightning/resolve/main/Qwen-Image-Edit-Lightning-4steps-V1.0.safetensors",
          "sha256": "VERIFY_qwen_lightning_edit_4s_v1",
          "size": 1825361920,
          "format": "safetensors",
          "precision": "fp32",
          "note": "Edit-specific, 4-step, V1.0. Fastest but slightly lower quality than 8-step."
        },
        {
          "id": "edit-4step-v1-bf16",
          "file": "Qwen-Image-Edit-Lightning-4steps-V1.0-bf16.safetensors",
          "url": "https://huggingface.co/lightx2v/Qwen-Image-Lightning/resolve/main/Qwen-Image-Edit-Lightning-4steps-V1.0-bf16.safetensors",
          "sha256": "d8132c32e7df906603dd6b072ff2fb0af88ab15ef0f3ac697a2011c8b47bbeb1",
          "size": 912680960,
          "format": "safetensors",
          "precision": "bf16",
          "note": "Edit-specific, 4-step, V1.0 in bf16."
        },
        {
          "id": "gen-8step-v2",
          "file": "Qwen-Image-Lightning-8steps-V2.0.safetensors",
          "url": "https://huggingface.co/lightx2v/Qwen-Image-Lightning/resolve/main/Qwen-Image-Lightning-8steps-V2.0.safetensors",
          "sha256": "VERIFY_qwen_lightning_gen_8s_v2",
          "size": 1825361920,
          "format": "safetensors",
          "precision": "fp32",
          "note": "Generation-focused, 8-step, V2.0. Latest version."
        },
        {
          "id": "gen-8step-v2-bf16",
          "file": "Qwen-Image-Lightning-8steps-V2.0-bf16.safetensors",
          "url": "https://huggingface.co/lightx2v/Qwen-Image-Lightning/resolve/main/Qwen-Image-Lightning-8steps-V2.0-bf16.safetensors",
          "sha256": "VERIFY_qwen_lightning_gen_8s_v2_bf16",
          "size": 912680960,
          "format": "safetensors",
          "precision": "bf16",
          "note": "Generation-focused, 8-step, V2.0 in bf16."
        },
        {
          "id": "gen-4step-v2",
          "file": "Qwen-Image-Lightning-4steps-V2.0.safetensors",
          "url": "https://huggingface.co/lightx2v/Qwen-Image-Lightning/resolve/main/Qwen-Image-Lightning-4steps-V2.0.safetensors",
          "sha256": "VERIFY_qwen_lightning_gen_4s_v2",
          "size": 1825361920,
          "format": "safetensors",
          "precision": "fp32",
          "note": "Generation-focused, 4-step, V2.0. Fastest generation."
        },
        {
          "id": "gen-4step-v2-bf16",
          "file": "Qwen-Image-Lightning-4steps-V2.0-bf16.safetensors",
          "url": "https://huggingface.co/lightx2v/Qwen-Image-Lightning/resolve/main/Qwen-Image-Lightning-4steps-V2.0-bf16.safetensors",
          "sha256": "VERIFY_qwen_lightning_gen_4s_v2_bf16",
          "size": 912680960,
          "format": "safetensors",
          "precision": "bf16",
          "note": "Generation-focused, 4-step, V2.0 in bf16."
        },
        {
          "id": "fp8-gen-4step-v1-bf16",
          "file": "Qwen-Image-fp8-e4m3fn-Lightning-4steps-V1.0-bf16.safetensors",
          "url": "https://huggingface.co/lightx2v/Qwen-Image-Lightning/resolve/main/Qwen-Image-fp8-e4m3fn-Lightning-4steps-V1.0-bf16.safetensors",
          "sha256": "VERIFY_qwen_lightning_fp8_4s_v1_bf16",
          "size": 912680960,
          "format": "safetensors",
          "precision": "bf16",
          "note": "Trained specifically for fp8 base model. 4-step, bf16."
        },
        {
          "id": "fp8-gen-4step-v1-fp32",
          "file": "Qwen-Image-fp8-e4m3fn-Lightning-4steps-V1.0-fp32.safetensors",
          "url": "https://huggingface.co/lightx2v/Qwen-Image-Lightning/resolve/main/Qwen-Image-fp8-e4m3fn-Lightning-4steps-V1.0-fp32.safetensors",
          "sha256": "VERIFY_qwen_lightning_fp8_4s_v1_fp32",
          "size": 1825361920,
          "format": "safetensors",
          "precision": "fp32",
          "note": "Trained specifically for fp8 base model. 4-step, fp32."
        }
      ],
      "recommended_weight": 1.0,
      "weight_range": [
        0.8,
        1.0
      ],
      "tags": [
        "qwen",
        "lora",
        "lightning",
        "distillation",
        "fast-inference",
        "comfyui"
      ],
      "rating": 4.7,
      "downloads": 773000,
      "added": "2025-08-01",
      "updated": "2025-10-01"
    },
    {
      "id": "qwen-image-vae",
      "name": "Qwen Image VAE",
      "type": "vae",
      "architecture": "qwen-image",
      "author": "Comfy-Org",
      "license": "apache-2.0",
      "homepage": "https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI",
      "description": "VAE for the Qwen Image Edit pipeline. Single file, no variants.\nRequired by all Qwen Image Edit checkpoints.\n",
      "file": {
        "url": "https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/vae/qwen_image_vae.safetensors",
        "sha256": "a70580f0213e67967ee9c95f05bb400e8fb08307e017a924bf3441223e023d1f",
        "size": 266338304,
        "format": "safetensors"
      },
      "tags": [
        "qwen",
        "vae",
        "comfyui"
      ],
      "rating": 5.0,
      "downloads": 275000,
      "added": "2025-07-01",
      "updated": "2025-07-01"
    },
    {
      "id": "realesrgan-x4plus",
      "name": "RealESRGAN x4plus",
      "type": "upscaler",
      "author": "xinntao",
      "license": "bsd-3-clause",
      "homepage": "https://github.com/xinntao/Real-ESRGAN",
      "description": "General-purpose 4x upscaler from the Real-ESRGAN project.\nGood balance of quality and speed. Works well for both\nphotos and AI-generated images.\n",
      "scale_factor": 4,
      "file": {
        "url": "https://huggingface.co/ai-forever/Real-ESRGAN/resolve/main/RealESRGAN_x4.pth",
        "sha256": "aa00f09ad753d88576b21ed977e97d634976377031b178acc3b5b238df463400",
        "size": 67040989,
        "format": "pth"
      },
      "tags": [
        "upscaler",
        "4x",
        "realesrgan",
        "general-purpose"
      ],
      "rating": 4.7,
      "downloads": 4500000,
      "added": "2022-06-01",
      "updated": "2024-01-01"
    },
    {
      "id": "sd-1.5",
      "name": "Stable Diffusion 1.5",
      "type": "checkpoint",
      "architecture": "sd15",
      "author": "runwayml",
      "license": "creativeml-openrail-m",
      "homepage": "https://huggingface.co/runwayml/stable-diffusion-v1-5",
      "description": "The original Stable Diffusion 1.5. Lightweight, fast, huge ecosystem\nof LoRAs, embeddings, and ControlNets. 512x512 native resolution.\n",
      "variants": [
        {
          "id": "fp16",
          "file": "v1-5-pruned-emaonly.safetensors",
          "url": "https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.safetensors",
          "sha256": "VERIFY_sd15_fp16",
          "size": 4265146304,
          "format": "safetensors",
          "precision": "fp16",
          "vram_required": 4096,
          "vram_recommended": 8192
        }
      ],
      "requires": [
        {
          "id": "sd-vae-ft-mse",
          "type": "vae",
          "reason": "Recommended VAE for SD 1.5 (sharper outputs)"
        }
      ],
      "defaults": {
        "steps": 25,
        "cfg": 7.5,
        "sampler": "dpmpp_2m",
        "scheduler": "karras"
      },
      "tags": [
        "sd15",
        "text-to-image",
        "stable-diffusion",
        "lightweight"
      ],
      "rating": 4.3,
      "downloads": 12000000,
      "added": "2022-10-20",
      "updated": "2024-01-01",
      "preview_images": [
        "https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly-demo-images/image_01.png"
      ]
    },
    {
      "id": "sd-2.1",
      "name": "Stable Diffusion 2.1",
      "type": "checkpoint",
      "architecture": "sd21",
      "author": "stabilityai",
      "license": "openrail++",
      "homepage": "https://huggingface.co/stabilityai/stable-diffusion-2-1",
      "description": "Stable Diffusion 2.1, fine-tuned from SD 2.0 with improved aesthetics.\nGenerates at 768x768 resolution. Uses OpenCLIP ViT-H/14 text encoder.\n",
      "file": {
        "url": "https://huggingface.co/stabilityai/stable-diffusion-2-1/resolve/main/v2-1_768-ema-pruned.safetensors",
        "sha256": "ad2a33c361c1f593c4a1571e8b1f328c6b1c7b7d8d5eabe3cee16e241c1f3b50",
        "size": 5214865152,
        "format": "safetensors"
      },
      "defaults": {
        "steps": 30,
        "cfg": 7.5,
        "sampler": "dpmpp_2m",
        "scheduler": "karras"
      },
      "tags": [
        "sd21",
        "text-to-image",
        "stable-diffusion",
        "768"
      ],
      "rating": 4.4,
      "downloads": 3200000,
      "added": "2022-12-07",
      "updated": "2024-01-01"
    },
    {
      "id": "sd-vae-ft-mse",
      "name": "SD VAE ft-MSE",
      "type": "vae",
      "architecture": "sd15",
      "author": "stabilityai",
      "license": "creativeml-openrail-m",
      "homepage": "https://huggingface.co/stabilityai/sd-vae-ft-mse",
      "description": "Fine-tuned VAE for Stable Diffusion 1.5. Produces sharper, more\ndetailed outputs compared to the default VAE. MSE-optimized.\n",
      "file": {
        "url": "https://huggingface.co/stabilityai/sd-vae-ft-mse/resolve/main/vae-ft-mse-840000-ema-pruned.safetensors",
        "sha256": "VERIFY_sd_vae_ft_mse",
        "size": 334695950,
        "format": "safetensors"
      },
      "tags": [
        "sd15",
        "vae",
        "fine-tuned",
        "mse"
      ],
      "rating": 4.7,
      "downloads": 6800000,
      "added": "2023-01-01",
      "updated": "2024-01-01"
    },
    {
      "id": "sd15-controlnet-canny",
      "name": "ControlNet v1.1 Canny (SD 1.5)",
      "type": "controlnet",
      "architecture": "sd15",
      "author": "lllyasviel",
      "license": "openrail",
      "homepage": "https://huggingface.co/lllyasviel/ControlNet-v1-1",
      "description": "ControlNet v1.1 for SD 1.5 — Canny edge detection conditioned generation.\nProvides structural control using canny edge maps. The most popular ControlNet.\n",
      "base_models": [
        "sd-1.5"
      ],
      "preprocessor": "canny",
      "file": {
        "url": "https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_canny.pth",
        "sha256": "f99cfe4c70910e38e3fece9918a4979ed7d3dcf9b81cee293e1755363af5406a",
        "size": 1557135360,
        "format": "pth"
      },
      "tags": [
        "sd15",
        "controlnet",
        "canny",
        "edge-detection"
      ],
      "rating": 4.8,
      "downloads": 4200000,
      "added": "2023-04-14",
      "updated": "2024-01-01"
    },
    {
      "id": "sd15-controlnet-depth",
      "name": "ControlNet v1.1 Depth (SD 1.5)",
      "type": "controlnet",
      "architecture": "sd15",
      "author": "lllyasviel",
      "license": "openrail",
      "homepage": "https://huggingface.co/lllyasviel/ControlNet-v1-1",
      "description": "ControlNet v1.1 for SD 1.5 — Depth map conditioned generation.\nUses MiDaS depth estimation maps for structural control.\n",
      "base_models": [
        "sd-1.5"
      ],
      "preprocessor": "depth_midas",
      "file": {
        "url": "https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11f1p_sd15_depth.pth",
        "sha256": "c48b0e8e0e22db42b8c6532b75cae8e8e8e8e0e25c8e4c2b8e6b1c0a0e0e0e0",
        "size": 1557135360,
        "format": "pth"
      },
      "tags": [
        "sd15",
        "controlnet",
        "depth",
        "midas"
      ],
      "rating": 4.7,
      "downloads": 3500000,
      "added": "2023-04-14",
      "updated": "2024-01-01"
    },
    {
      "id": "sd15-controlnet-openpose",
      "name": "ControlNet v1.1 OpenPose (SD 1.5)",
      "type": "controlnet",
      "architecture": "sd15",
      "author": "lllyasviel",
      "license": "openrail",
      "homepage": "https://huggingface.co/lllyasviel/ControlNet-v1-1",
      "description": "ControlNet v1.1 for SD 1.5 — OpenPose body pose conditioned generation.\nUses human pose skeleton for structural control. Great for character posing.\n",
      "base_models": [
        "sd-1.5"
      ],
      "preprocessor": "openpose",
      "file": {
        "url": "https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_openpose.pth",
        "sha256": "VERIFY_sd15_controlnet_openpose",
        "size": 1557135360,
        "format": "pth"
      },
      "tags": [
        "sd15",
        "controlnet",
        "openpose",
        "pose"
      ],
      "rating": 4.7,
      "downloads": 3100000,
      "added": "2023-04-14",
      "updated": "2024-01-01"
    },
    {
      "id": "sdxl-base-1.0",
      "name": "Stable Diffusion XL Base 1.0",
      "type": "checkpoint",
      "architecture": "sdxl",
      "author": "stabilityai",
      "license": "openrail++",
      "homepage": "https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0",
      "description": "Stable Diffusion XL base model. High resolution text-to-image generation\nat 1024x1024. Works great with LoRAs and ControlNets.\n",
      "variants": [
        {
          "id": "fp16",
          "file": "sd_xl_base_1.0.safetensors",
          "url": "https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_base_1.0.safetensors",
          "sha256": "31e35c80fc4829d14f90153f4c74cd59c90b779f6afe05a74cd6120b893f7e5b",
          "size": 6938078334,
          "format": "safetensors",
          "precision": "fp16",
          "vram_required": 8192,
          "vram_recommended": 12288
        }
      ],
      "requires": [
        {
          "id": "sdxl-vae-fp16-fix",
          "type": "vae",
          "reason": "Recommended VAE for SDXL (fixes fp16 NaN issues)"
        }
      ],
      "defaults": {
        "steps": 30,
        "cfg": 7.0,
        "sampler": "dpmpp_2m",
        "scheduler": "karras"
      },
      "preview_images": [
        "https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/output.png"
      ],
      "tags": [
        "sdxl",
        "text-to-image",
        "stable-diffusion",
        "high-resolution"
      ],
      "rating": 4.6,
      "downloads": 5400000,
      "added": "2023-07-26",
      "updated": "2024-06-01"
    },
    {
      "id": "sdxl-controlnet-canny",
      "name": "ControlNet Canny (SDXL)",
      "type": "controlnet",
      "architecture": "sdxl",
      "author": "diffusers",
      "license": "openrail++",
      "homepage": "https://huggingface.co/diffusers/controlnet-canny-sdxl-1.0",
      "description": "ControlNet trained on SDXL for Canny edge detection conditioning.\nSingle-file diffusers-format model for structural control in SDXL.\n",
      "base_models": [
        "sdxl-base-1.0"
      ],
      "preprocessor": "canny",
      "variants": [
        {
          "id": "fp16",
          "file": "diffusion_pytorch_model.fp16.safetensors",
          "url": "https://huggingface.co/diffusers/controlnet-canny-sdxl-1.0/resolve/main/diffusion_pytorch_model.fp16.safetensors",
          "sha256": "b2e7d3921058a442cc80430d1ec8847f42599c705e2451c95e77cf4dcf8d6c25",
          "size": 2502139904,
          "format": "safetensors",
          "precision": "fp16",
          "vram_required": 8192
        },
        {
          "id": "fp32",
          "file": "diffusion_pytorch_model.safetensors",
          "url": "https://huggingface.co/diffusers/controlnet-canny-sdxl-1.0/resolve/main/diffusion_pytorch_model.safetensors",
          "sha256": "VERIFY_sdxl_controlnet_canny_fp32",
          "size": 5004279808,
          "format": "safetensors",
          "precision": "fp32",
          "vram_required": 16384
        }
      ],
      "tags": [
        "sdxl",
        "controlnet",
        "canny",
        "edge-detection"
      ],
      "rating": 4.6,
      "downloads": 1500000,
      "added": "2023-09-01",
      "updated": "2024-06-01"
    },
    {
      "id": "sdxl-refiner-1.0",
      "name": "SDXL Refiner 1.0",
      "type": "checkpoint",
      "architecture": "sdxl",
      "author": "stabilityai",
      "license": "openrail++",
      "homepage": "https://huggingface.co/stabilityai/stable-diffusion-xl-refiner-1.0",
      "description": "SDXL 1.0 Refiner — small-detail expert model. Used as a second pass\nto add fine details to images generated by SDXL Base.\n",
      "file": {
        "url": "https://huggingface.co/stabilityai/stable-diffusion-xl-refiner-1.0/resolve/main/sd_xl_refiner_1.0.safetensors",
        "sha256": "7440042bbdc8a24813002c09b6b69b64dc90fded4472613437b7f55f9b7d9c5f",
        "size": 6527995904,
        "format": "safetensors"
      },
      "requires": [
        {
          "id": "sdxl-vae-fp16-fix",
          "type": "vae",
          "reason": "Recommended VAE for SDXL"
        }
      ],
      "defaults": {
        "steps": 20,
        "cfg": 3.5,
        "sampler": "dpmpp_2m",
        "scheduler": "karras"
      },
      "tags": [
        "sdxl",
        "refiner",
        "detail",
        "stable-diffusion"
      ],
      "rating": 4.5,
      "downloads": 1800000,
      "added": "2023-07-26",
      "updated": "2024-06-01"
    },
    {
      "id": "sdxl-turbo",
      "name": "SDXL Turbo",
      "type": "checkpoint",
      "architecture": "sdxl",
      "author": "stabilityai",
      "license": "sai-nc-community",
      "homepage": "https://huggingface.co/stabilityai/sdxl-turbo",
      "description": "SDXL Turbo — distilled from SDXL 1.0 using Adversarial Diffusion Distillation.\nGenerates images in 1-4 steps at 512x512. Great for real-time applications.\n",
      "variants": [
        {
          "id": "fp16",
          "file": "sd_xl_turbo_1.0_fp16.safetensors",
          "url": "https://huggingface.co/stabilityai/sdxl-turbo/resolve/main/sd_xl_turbo_1.0_fp16.safetensors",
          "sha256": "e869ac7d6942cb327d68d5ed83a40447aadf20e0c3358d98b2cc9e270db0da26",
          "size": 6451034624,
          "format": "safetensors",
          "precision": "fp16",
          "vram_required": 6144,
          "vram_recommended": 8192
        },
        {
          "id": "fp32",
          "file": "sd_xl_turbo_1.0.safetensors",
          "url": "https://huggingface.co/stabilityai/sdxl-turbo/resolve/main/sd_xl_turbo_1.0.safetensors",
          "sha256": "VERIFY_sdxl_turbo_fp32",
          "size": 13902070784,
          "format": "safetensors",
          "precision": "fp32",
          "vram_required": 12288,
          "vram_recommended": 16384
        }
      ],
      "requires": [
        {
          "id": "sdxl-vae-fp16-fix",
          "type": "vae",
          "reason": "Recommended VAE for SDXL"
        }
      ],
      "defaults": {
        "steps": 1,
        "cfg": 0.0,
        "sampler": "euler_ancestral",
        "scheduler": "normal"
      },
      "tags": [
        "sdxl",
        "turbo",
        "fast",
        "text-to-image",
        "distilled"
      ],
      "rating": 4.7,
      "downloads": 2800000,
      "added": "2023-11-28",
      "updated": "2024-06-01"
    },
    {
      "id": "sdxl-vae-fp16-fix",
      "name": "SDXL VAE (fp16 NaN fix)",
      "type": "vae",
      "architecture": "sdxl",
      "author": "madebyollin",
      "license": "apache-2.0",
      "homepage": "https://huggingface.co/madebyollin/sdxl-vae-fp16-fix",
      "description": "Fixed SDXL VAE that works correctly in fp16 precision.\nThe original SDXL VAE produces NaN values in fp16 mode — this version\nfixes that issue. Recommended for all SDXL workflows.\n",
      "file": {
        "url": "https://huggingface.co/madebyollin/sdxl-vae-fp16-fix/resolve/main/diffusion_pytorch_model.safetensors",
        "sha256": "63aeecb90ff7bc1c115395962d3e803571385b61938377bc7089b36e81e92e2e",
        "size": 334643268,
        "format": "safetensors"
      },
      "tags": [
        "sdxl",
        "vae",
        "fp16-fix"
      ],
      "rating": 4.9,
      "downloads": 4100000,
      "added": "2023-08-15",
      "updated": "2024-01-01"
    },
    {
      "id": "t5-xxl-fp16",
      "name": "T5-XXL Text Encoder (fp16)",
      "type": "text_encoder",
      "architecture": "t5",
      "author": "comfyanonymous",
      "license": "apache-2.0",
      "homepage": "https://huggingface.co/comfyanonymous/flux_text_encoders",
      "description": "T5-XXL text encoder in fp16 precision. Required by FLUX models\nfor prompt processing. Large model — 9.8 GB.\nUse fp8 variant if you have less than 24 GB VRAM.\n",
      "variants": [
        {
          "id": "fp16",
          "file": "t5xxl_fp16.safetensors",
          "url": "https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/t5xxl_fp16.safetensors",
          "sha256": "VERIFY_t5xxl_fp16",
          "size": 9787849216,
          "format": "safetensors",
          "precision": "fp16",
          "vram_required": 12288,
          "vram_recommended": 16384
        }
      ],
      "tags": [
        "t5",
        "text-encoder",
        "flux",
        "fp16"
      ],
      "rating": 5.0,
      "downloads": 2400000,
      "added": "2024-08-01",
      "updated": "2024-08-01"
    },
    {
      "id": "t5-xxl-fp8",
      "name": "T5-XXL Text Encoder (fp8)",
      "type": "text_encoder",
      "architecture": "t5",
      "author": "comfyanonymous",
      "license": "apache-2.0",
      "homepage": "https://huggingface.co/comfyanonymous/flux_text_encoders",
      "description": "T5-XXL text encoder quantized to fp8 precision. Uses half the VRAM\nof the fp16 version with minimal quality impact.\nRecommended for 12-16 GB VRAM setups using FLUX models.\n",
      "variants": [
        {
          "id": "fp8",
          "file": "t5xxl_fp8_e4m3fn.safetensors",
          "url": "https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/t5xxl_fp8_e4m3fn.safetensors",
          "sha256": "7d330da4816157540d6bb7838bf63a0f02f573fc48ca4d8de34bb0cbfd514f09",
          "size": 4893843456,
          "format": "safetensors",
          "precision": "fp8-e4m3fn",
          "vram_required": 6144,
          "vram_recommended": 8192
        }
      ],
      "tags": [
        "t5",
        "text-encoder",
        "flux",
        "fp8",
        "quantized"
      ],
      "rating": 4.8,
      "downloads": 1800000,
      "added": "2024-08-01",
      "updated": "2024-08-01"
    },
    {
      "id": "z-image-text-encoder",
      "name": "Z-Image Qwen 3 4B Text Encoder",
      "type": "text_encoder",
      "architecture": "qwen3",
      "author": "Comfy-Org",
      "license": "apache-2.0",
      "homepage": "https://huggingface.co/Comfy-Org/z_image_turbo",
      "description": "Qwen 3 4B text encoder used by Z-Image-Turbo.\nAvailable in bf16 (full precision), fp8_mixed (reduced VRAM), and fp4_mixed (minimum VRAM).\nPlace in models/text_encoders/ and load with CLIPLoader node.\n",
      "variants": [
        {
          "id": "bf16",
          "file": "qwen_3_4b.safetensors",
          "url": "https://huggingface.co/Comfy-Org/z_image_turbo/resolve/main/split_files/text_encoders/qwen_3_4b.safetensors",
          "sha256": "6c671498573ac2f7a5501502ccce8d2b08ea6ca2f661c458e708f36b36edfc5a",
          "size": 8633139200,
          "format": "safetensors",
          "precision": "bf16",
          "vram_required": 10240,
          "vram_recommended": 12288,
          "note": "Full precision bf16. Best quality text encoding."
        },
        {
          "id": "fp8-mixed",
          "file": "qwen_3_4b_fp8_mixed.safetensors",
          "url": "https://huggingface.co/Comfy-Org/z_image_turbo/resolve/main/split_files/text_encoders/qwen_3_4b_fp8_mixed.safetensors",
          "sha256": "VERIFY_z_image_qwen3_4b_fp8_mixed",
          "size": 6044237824,
          "format": "safetensors",
          "precision": "fp8-e4m3fn",
          "vram_required": 8192,
          "vram_recommended": 10240,
          "note": "Mixed fp8 quantization. Good quality with reduced VRAM."
        },
        {
          "id": "fp4-mixed",
          "file": "qwen_3_4b_fp4_mixed.safetensors",
          "url": "https://huggingface.co/Comfy-Org/z_image_turbo/resolve/main/split_files/text_encoders/qwen_3_4b_fp4_mixed.safetensors",
          "sha256": "VERIFY_z_image_qwen3_4b_fp4_mixed",
          "size": 3736076288,
          "format": "safetensors",
          "precision": "fp4",
          "vram_required": 4096,
          "vram_recommended": 6144,
          "note": "Mixed fp4 quantization. Minimum VRAM, some quality reduction."
        }
      ],
      "tags": [
        "z-image",
        "text-encoder",
        "qwen3",
        "comfyui"
      ],
      "rating": 4.8
    },
    {
      "id": "z-image-turbo",
      "name": "Z-Image-Turbo",
      "type": "diffusion_model",
      "architecture": "z-image",
      "author": "Tongyi-MAI / Comfy-Org / jayn7",
      "license": "apache-2.0",
      "homepage": "https://huggingface.co/Comfy-Org/z_image_turbo",
      "description": "Distilled 6B parameter text-to-image model from Alibaba Tongyi Lab.\nUses Scalable Single-Stream DiT (S3-DiT) architecture for maximum parameter efficiency.\nSub-second inference latency on H800 GPUs, fits within 16GB VRAM consumer devices.\nOnly 8 NFEs (steps) needed. Use euler sampler, guidance_scale 0.0.\nExcels at photorealistic generation and accurate bilingual text rendering (English & Chinese).\nAvailable as native safetensors (bf16/nvfp4) or GGUF quantizations.\n",
      "variants": [
        {
          "id": "bf16",
          "file": "z_image_turbo_bf16.safetensors",
          "url": "https://huggingface.co/Comfy-Org/z_image_turbo/resolve/main/split_files/diffusion_models/z_image_turbo_bf16.safetensors",
          "sha256": "2407613050b809ffdff18a4ac99af83ea6b95443ecebdf80e064a79c825574a6",
          "size": 13207024640,
          "format": "safetensors",
          "precision": "bf16",
          "vram_required": 16384,
          "vram_recommended": 24576,
          "note": "Full precision bf16. Best quality."
        },
        {
          "id": "nvfp4",
          "file": "z_image_turbo_nvfp4.safetensors",
          "url": "https://huggingface.co/Comfy-Org/z_image_turbo/resolve/main/split_files/diffusion_models/z_image_turbo_nvfp4.safetensors",
          "sha256": "VERIFY_z_image_turbo_nvfp4",
          "size": 4843151360,
          "format": "safetensors",
          "precision": "nvfp4",
          "vram_required": 8192,
          "vram_recommended": 12288,
          "note": "NVIDIA fp4 quantization. Lower VRAM usage with minimal quality loss."
        },
        {
          "id": "gguf-q8-0",
          "file": "z_image_turbo-Q8_0.gguf",
          "url": "https://huggingface.co/jayn7/Z-Image-Turbo-GGUF/resolve/main/z_image_turbo-Q8_0.gguf",
          "sha256": "f163d60b0eb427469510b8226243d196574a18139a2e40c017409cfbda95ecfe",
          "size": 7755268096,
          "format": "gguf",
          "precision": "q8_0",
          "vram_required": 10240,
          "vram_recommended": 12288,
          "note": "GGUF Q8_0 — best GGUF quality. Requires ComfyUI-GGUF custom node."
        },
        {
          "id": "gguf-q6-k",
          "file": "z_image_turbo-Q6_K.gguf",
          "url": "https://huggingface.co/jayn7/Z-Image-Turbo-GGUF/resolve/main/z_image_turbo-Q6_K.gguf",
          "sha256": "fc137d87b49e06fdd5230d67d6c8cfa42a9e1fd38b65ccd355882450c3eb1c82",
          "size": 6346129408,
          "format": "gguf",
          "precision": "q6_k",
          "vram_required": 8192,
          "vram_recommended": 10240,
          "note": "GGUF Q6_K — good quality/size balance."
        },
        {
          "id": "gguf-q5-k-m",
          "file": "z_image_turbo-Q5_K_M.gguf",
          "url": "https://huggingface.co/jayn7/Z-Image-Turbo-GGUF/resolve/main/z_image_turbo-Q5_K_M.gguf",
          "sha256": "VERIFY_z_image_gguf_q5_k_m",
          "size": 5926789120,
          "format": "gguf",
          "precision": "q5_k_m",
          "vram_required": 8192,
          "vram_recommended": 10240,
          "note": "GGUF Q5_K_M — recommended for 8GB+ GPUs."
        },
        {
          "id": "gguf-q5-k-s",
          "file": "z_image_turbo-Q5_K_S.gguf",
          "url": "https://huggingface.co/jayn7/Z-Image-Turbo-GGUF/resolve/main/z_image_turbo-Q5_K_S.gguf",
          "sha256": "VERIFY_z_image_gguf_q5_k_s",
          "size": 5572034560,
          "format": "gguf",
          "precision": "q5_k_s",
          "vram_required": 8192,
          "vram_recommended": 10240,
          "note": "GGUF Q5_K_S — smaller Q5 variant."
        },
        {
          "id": "gguf-q4-k-m",
          "file": "z_image_turbo-Q4_K_M.gguf",
          "url": "https://huggingface.co/jayn7/Z-Image-Turbo-GGUF/resolve/main/z_image_turbo-Q4_K_M.gguf",
          "sha256": "VERIFY_z_image_gguf_q4_k_m",
          "size": 5346283520,
          "format": "gguf",
          "precision": "q4_k_m",
          "vram_required": 6144,
          "vram_recommended": 8192,
          "note": "GGUF Q4_K_M — good for 8GB GPUs."
        },
        {
          "id": "gguf-q4-k-s",
          "file": "z_image_turbo-Q4_K_S.gguf",
          "url": "https://huggingface.co/jayn7/Z-Image-Turbo-GGUF/resolve/main/z_image_turbo-Q4_K_S.gguf",
          "sha256": "VERIFY_z_image_gguf_q4_k_s",
          "size": 5003804672,
          "format": "gguf",
          "precision": "q4_k_s",
          "vram_required": 6144,
          "vram_recommended": 8192,
          "note": "GGUF Q4_K_S — smaller Q4 variant."
        },
        {
          "id": "gguf-q3-k-m",
          "file": "z_image_turbo-Q3_K_M.gguf",
          "url": "https://huggingface.co/jayn7/Z-Image-Turbo-GGUF/resolve/main/z_image_turbo-Q3_K_M.gguf",
          "sha256": "VERIFY_z_image_gguf_q3_k_m",
          "size": 4424990720,
          "format": "gguf",
          "precision": "q3_k_m",
          "vram_required": 6144,
          "vram_recommended": 8192,
          "note": "GGUF Q3_K_M — for 6GB+ GPUs. Noticeable quality reduction."
        },
        {
          "id": "gguf-q3-k-s",
          "file": "z_image_turbo-Q3_K_S.gguf",
          "url": "https://huggingface.co/jayn7/Z-Image-Turbo-GGUF/resolve/main/z_image_turbo-Q3_K_S.gguf",
          "sha256": "VERIFY_z_image_gguf_q3_k_s",
          "size": 4069449728,
          "format": "gguf",
          "precision": "q3_k_s",
          "vram_required": 6144,
          "vram_recommended": 8192,
          "note": "GGUF Q3_K_S — smaller Q3 variant."
        }
      ],
      "requires": [
        {
          "id": "z-image-text-encoder",
          "type": "text_encoder",
          "reason": "Qwen 3 4B text encoder for prompt processing"
        },
        {
          "id": "z-image-vae",
          "type": "vae",
          "reason": "Z-Image VAE for decoding latents to images"
        }
      ],
      "recommended": {
        "steps": 8,
        "cfg": 0.0,
        "sampler": "euler",
        "scheduler": "simple"
      },
      "tags": [
        "z-image",
        "text-to-image",
        "turbo",
        "fast-inference",
        "bilingual",
        "comfyui",
        "gguf"
      ],
      "preview_images": [
        "https://huggingface.co/Comfy-Org/z_image_turbo/resolve/main/z_image_turbo_example.png"
      ],
      "rating": 4.9
    },
    {
      "id": "z-image-turbo-controlnet-union",
      "name": "Z-Image-Turbo Fun ControlNet Union",
      "type": "controlnet",
      "architecture": "z-image",
      "author": "alibaba-pai",
      "license": "apache-2.0",
      "homepage": "https://huggingface.co/alibaba-pai/Z-Image-Turbo-Fun-Controlnet-Union",
      "description": "ControlNet union model for Z-Image-Turbo.\nSupports Canny, HED, Depth, Pose, and MLSD control conditions.\nAdjust control_context_scale (0.65–0.80) for best results.\nUse with detailed prompts for better stability.\nV2.0 with inpaint mode also available separately.\n",
      "file": {
        "name": "Z-Image-Turbo-Fun-Controlnet-Union.safetensors",
        "url": "https://huggingface.co/alibaba-pai/Z-Image-Turbo-Fun-Controlnet-Union/resolve/main/Z-Image-Turbo-Fun-Controlnet-Union.safetensors",
        "sha256": "86c085c0d7853f12ce5183499934b54d08371c60f549c5a6b20615cd23989388",
        "size": 3328599040,
        "format": "safetensors"
      },
      "requires": [
        {
          "id": "z-image-turbo",
          "type": "diffusion_model",
          "reason": "Requires Z-Image-Turbo as the base diffusion model"
        }
      ],
      "tags": [
        "z-image",
        "controlnet",
        "canny",
        "depth",
        "pose",
        "comfyui"
      ],
      "rating": 4.6
    },
    {
      "id": "z-image-turbo-distill-lora",
      "name": "Z-Image-Turbo Distill Patch LoRA",
      "type": "lora",
      "architecture": "z-image",
      "author": "Comfy-Org",
      "license": "apache-2.0",
      "homepage": "https://huggingface.co/Comfy-Org/z_image_turbo",
      "description": "Distillation patch LoRA for Z-Image-Turbo.\nUsed to enable the base Z-Image model to run with fewer steps (turbo mode).\nApply via LoraLoader node with strength 1.0.\n",
      "file": {
        "name": "z_image_turbo_distill_patch_lora_bf16.safetensors",
        "url": "https://huggingface.co/Comfy-Org/z_image_turbo/resolve/main/split_files/loras/z_image_turbo_distill_patch_lora_bf16.safetensors",
        "sha256": "VERIFY_z_image_distill_lora",
        "size": 166723584,
        "format": "safetensors"
      },
      "tags": [
        "z-image",
        "lora",
        "distillation",
        "comfyui"
      ],
      "rating": 4.7
    },
    {
      "id": "z-image-vae",
      "name": "Z-Image VAE",
      "type": "vae",
      "architecture": "z-image",
      "author": "Comfy-Org",
      "license": "apache-2.0",
      "homepage": "https://huggingface.co/Comfy-Org/z_image_turbo",
      "description": "VAE for Z-Image-Turbo. Decodes latents to images.\nPlace in models/vae/ and load with VAELoader node.\n",
      "file": {
        "name": "z-image-vae.safetensors",
        "url": "https://huggingface.co/Comfy-Org/z_image_turbo/resolve/main/split_files/vae/ae.safetensors",
        "sha256": "afc8e28272cd15db3919bacdb6918ce9c1ed22e96cb12c4d5ed0fba823529e38",
        "size": 351272960,
        "format": "safetensors"
      },
      "tags": [
        "z-image",
        "vae",
        "comfyui"
      ],
      "rating": 5.0
    }
  ]
}